discovery.docker "containers" {
  host = "unix:///var/run/docker.sock"
  refresh_interval = "5s"
}

discovery.relabel "docker_logs" {
  targets = discovery.docker.containers.targets

  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = ".*(loki|alloy).*"
    action        = "drop"
  }

  rule {
    source_labels = ["__meta_docker_container_id"]
    target_label  = "__path__"
    replacement   = "/var/lib/docker/containers/$1/$1-json.log"
  }

  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "/(.*)"
    target_label  = "container"
  }

  rule {
    source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
    regex         = "(.+)"
    target_label  = "service"
    replacement   = "$1"
  }

  rule {
    source_labels = ["service", "container"]
    regex         = "^;(.+)$"
    target_label  = "service"
    replacement   = "$1"
  }

  rule {
    source_labels = ["service"]
    target_label  = "service_name"
  }

  rule {
    source_labels = ["service_name"]
    regex         = "^$"
    target_label  = "service_name"
    replacement   = "unknown_service"
  }

  rule {
    source_labels = ["service_name", "container"]
    regex         = "unknown_service;(.+)"
    target_label  = "service_name"
    replacement   = "$1"
  }

  rule {
    source_labels = ["__meta_docker_container_log_stream"]
    target_label  = "logstream"
  }

  rule {
    source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
    target_label  = "compose_service"
  }

  rule {
    source_labels = ["__meta_docker_container_label_com_docker_compose_project"]
    target_label  = "compose_project"
  }

  rule {
    target_label = "job"
    replacement  = "docker"
  }
}

loki.source.docker "containers" {
  host             = "unix:///var/run/docker.sock"
  targets          = discovery.relabel.docker_logs.output
  forward_to       = [loki.process.docker_logs.receiver]
  relabel_rules    = discovery.relabel.docker_logs.rules
}

loki.process "docker_logs" {
  // Drop corrupted logs (control characters)
  stage.drop {
    expression = ".*[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F].*"
    drop_counter_reason = "corrupted_log"
  }

  stage.drop {
    older_than = "24h"
    drop_counter_reason = "log_too_old"
  }

  forward_to = [loki.write.default.receiver]
}

local.file_match "system_logs" {
  path_targets = [{
    __address__ = "localhost",
    __path__    = "/var/log/*.log",
    job         = "varlogs",
    service     = "varlogs",
    service_name = "varlogs",
  }]
}

discovery.relabel "system_logs" {
  targets = local.file_match.system_logs.targets

  rule {
    source_labels = ["__path__"]
    regex         = ".*(apport|dpkg|ubuntu-advantage|vmware|alternatives|bootstrap|cloud-init).*\\.log"
    action        = "drop"
  }
}

loki.source.file "system" {
  targets    = discovery.relabel.system_logs.output
  forward_to = [loki.process.system_logs.receiver]
}

loki.process "system_logs" {
  stage.regex {
    expression = "^(?P<timestamp>\\w{3}\\s+\\d+\\s+\\d{2}:\\d{2}:\\d{2})\\s+(?P<hostname>\\S+)\\s+(?P<process>\\S+):\\s+(?P<message>.*)"
  }

  stage.match {
    selector = "{filename=~\"/var/log/syslog\"} |~ \"(?i)(info|debug)\""
    action   = "drop"
    drop_counter_reason = "syslog_noise"
  }

  stage.match {
    selector = "{filename=~\"/var/log/kern.log\"} |~ \"(?i)(veth|br-|docker|promiscuous|forwarding state|disabled state|blocking state)\""
    action   = "drop"
    drop_counter_reason = "docker_network_noise"
  }

  stage.labels {
    values = {
      level = "",
    }
  }

  stage.timestamp {
    source = "timestamp"
    format = "Jan 02 15:04:05"
  }

  forward_to = [loki.write.default.receiver]
}

discovery.relabel "exporter_logs" {
  targets = discovery.docker.containers.targets

  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = ".*exporter.*"
    action        = "keep"
  }

  rule {
    source_labels = ["__meta_docker_container_id"]
    target_label  = "__path__"
    replacement   = "/var/lib/docker/containers/$1/$1-json.log"
  }

  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "/(.*)"
    target_label  = "exporter_name"
  }

  rule {
    source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
    target_label  = "service"
  }

  rule {
    target_label = "job"
    replacement  = "exporters"
  }
}

loki.source.docker "exporters" {
  host             = "unix:///var/run/docker.sock"
  targets          = discovery.relabel.exporter_logs.output
  forward_to       = [loki.process.exporter_logs.receiver]
  relabel_rules    = discovery.relabel.exporter_logs.rules
}

loki.process "exporter_logs" {
  stage.drop {
    expression = ".*[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F].*"
    drop_counter_reason = "corrupted_log"
  }

  stage.drop {
    older_than = "24h"
    drop_counter_reason = "log_too_old"
  }

  forward_to = [loki.write.default.receiver]
}

loki.write "default" {
  endpoint {
    url = "http://loki:3100/loki/api/v1/push"
    tenant_id = "1"
  }
}

otelcol.receiver.otlp "default" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }

  http {
    endpoint = "0.0.0.0:4318"
  }

  output {
    metrics = [otelcol.processor.memory_limiter.default.input]
    traces  = [otelcol.processor.memory_limiter.default.input]
    logs    = [otelcol.processor.memory_limiter.default.input]
  }
}

otelcol.processor.memory_limiter "default" {
  check_interval = "1s"
  limit          = "3500MiB"
  spike_limit    = "512MiB"

  output {
    metrics = [otelcol.processor.batch.default.input]
    traces  = [otelcol.processor.batch.default.input]
    logs    = [otelcol.processor.batch.default.input]
  }
}

otelcol.processor.batch "default" {
  timeout             = "5s"
  send_batch_size     = 8192
  send_batch_max_size = 10000

  output {
    metrics = [otelcol.exporter.prometheus.otlp_metrics.input]
    traces  = [otelcol.exporter.otlp.tempo.input]
    logs    = [otelcol.exporter.loki.otlp_logs.input]
  }
}

otelcol.exporter.prometheus "otlp_metrics" {
  forward_to = [prometheus.remote_write.mimir.receiver]
}

otelcol.exporter.loki "otlp_logs" {
  forward_to = [loki.write.default.receiver]
}

otelcol.exporter.otlp "tempo" {
  client {
    endpoint = "tempo:4317"
    tls {
      insecure = true
    }
  }
}

// ============================================================================
// PROMETHEUS METRICS COLLECTION
// ============================================================================

discovery.file "node_targets" {
  files = ["/etc/alloy/targets/node.json"]
}

discovery.file "cadvisor_targets" {
  files = ["/etc/alloy/targets/cadvisor.json"]
}

discovery.file "nginx_targets" {
  files = ["/etc/alloy/targets/nginx.json"]
}

discovery.file "mongodb_targets" {
  files = ["/etc/alloy/targets/mongodb.json"]
}

discovery.file "postgres_targets" {
  files = ["/etc/alloy/targets/postgres.json"]
}

discovery.file "blackbox_liveness_targets" {
  files = ["/etc/alloy/targets/blackbox-liveness.json"]
}

discovery.file "blackbox_readiness_targets" {
  files = ["/etc/alloy/targets/blackbox-readiness.json"]
}

// ============================================================================
// INTERNAL LGTM STACK SERVICES
// ============================================================================

prometheus.scrape "alertmanager" {
  targets = [{
    __address__ = "alertmanager:9093",
  }]
  forward_to = [prometheus.relabel.add_job_label_alertmanager.receiver]
  scrape_interval = "15s"
}

prometheus.scrape "alloy_internal" {
  targets = [{
    __address__ = "localhost:12345",
  }]
  forward_to = [prometheus.relabel.add_job_label_alloy.receiver]
  scrape_interval = "15s"
}

prometheus.scrape "loki" {
  targets = [{
    __address__ = "loki:3100",
  }]
  forward_to = [prometheus.relabel.add_job_label_loki.receiver]
  scrape_interval = "15s"
}

prometheus.scrape "tempo" {
  targets = [{
    __address__ = "tempo:3200",
  }]
  forward_to = [prometheus.relabel.add_job_label_tempo.receiver]
  scrape_interval = "15s"
}

prometheus.scrape "mimir" {
  targets = [{
    __address__ = "mimir:9009",
  }]
  forward_to = [prometheus.relabel.add_job_label_mimir.receiver]
  scrape_interval = "15s"
}

prometheus.relabel "add_job_label_alertmanager" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  
  rule {
    target_label = "job"
    replacement  = "alertmanager"
  }
}

prometheus.relabel "add_job_label_alloy" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  
  rule {
    target_label = "job"
    replacement  = "alloy"
  }
}

prometheus.relabel "add_job_label_loki" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  
  rule {
    target_label = "job"
    replacement  = "loki"
  }
}

prometheus.relabel "add_job_label_tempo" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  
  rule {
    target_label = "job"
    replacement  = "tempo"
  }
}

prometheus.relabel "add_job_label_mimir" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  
  rule {
    target_label = "job"
    replacement  = "mimir"
  }
}

// ============================================================================
// NODE EXPORTER - LOCAL (MONITORING SERVER)
// ============================================================================

prometheus.scrape "node_exporter_local" {
  targets = [{
    __address__ = "node-exporter:9100",
    instance = "monitoring-server",
    environment = "production",
    role = "monitoring",
  }]
  forward_to = [prometheus.relabel.add_job_label_node_local.receiver]
  scrape_interval = "30s"
  scrape_timeout = "25s"
}

prometheus.relabel "add_job_label_node_local" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  
  rule {
    target_label = "job"
    replacement  = "node-exporter-local"
  }
}

// ============================================================================
// NODE EXPORTER - REMOTE SERVERS
// ============================================================================

prometheus.scrape "node_exporter" {
  targets = discovery.file.node_targets.targets
  forward_to = [prometheus.remote_write.mimir.receiver]
  scrape_interval = "15s"
}

// ============================================================================
// CADVISOR
// ============================================================================

prometheus.scrape "cadvisor" {
  targets = discovery.file.cadvisor_targets.targets
  forward_to = [prometheus.relabel.add_job_label_cadvisor.receiver]
  scrape_interval = "15s"
}

prometheus.relabel "add_job_label_cadvisor" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  
  rule {
    target_label = "job"
    replacement  = "cadvisor"
  }
}

// ============================================================================
// NGINX EXPORTER
// ============================================================================

prometheus.scrape "nginx" {
  targets = discovery.file.nginx_targets.targets
  forward_to = [prometheus.relabel.add_job_label_nginx.receiver]
  scrape_interval = "15s"
}

prometheus.relabel "add_job_label_nginx" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  
  rule {
    target_label = "job"
    replacement  = "nginx"
  }
}

// ============================================================================
// MONGODB EXPORTER
// ============================================================================

prometheus.scrape "mongodb" {
  targets = discovery.file.mongodb_targets.targets
  forward_to = [prometheus.remote_write.mimir.receiver]
  scrape_interval = "15s"
}

// ============================================================================
// POSTGRESQL EXPORTER
// ============================================================================

prometheus.scrape "postgres" {
  targets = discovery.file.postgres_targets.targets
  forward_to = [prometheus.remote_write.mimir.receiver]
  scrape_interval = "15s"
}

// ============================================================================
// BLACKBOX EXPORTER - HTTP LIVENESS PROBES
// ============================================================================

discovery.relabel "blackbox_liveness" {
  targets = discovery.file.blackbox_liveness_targets.targets
  
  rule {
    source_labels = ["__address__"]
    target_label  = "__param_target"
  }
  
  rule {
    source_labels = ["__param_target"]
    target_label  = "instance"
  }
  
  rule {
    target_label = "__address__"
    replacement  = "blackbox-exporter:9115"
  }
  
  rule {
    source_labels = ["__param_target"]
    regex         = "http://([^:]+):.*"
    target_label  = "service"
    replacement   = "$1"
  }
}

prometheus.scrape "blackbox_http_liveness" {
  targets = discovery.relabel.blackbox_liveness.output
  forward_to = [prometheus.relabel.add_job_label_blackbox_liveness.receiver]
  scrape_interval = "15s"
  metrics_path = "/probe"
  params = {
    module = ["http_liveness"],
  }
}

prometheus.relabel "add_job_label_blackbox_liveness" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  
  rule {
    target_label = "job"
    replacement  = "blackbox-http-liveness"
  }
}

// ============================================================================
// BLACKBOX EXPORTER - HTTP READINESS PROBES
// ============================================================================

discovery.relabel "blackbox_readiness" {
  targets = discovery.file.blackbox_readiness_targets.targets
  
  rule {
    source_labels = ["__address__"]
    target_label  = "__param_target"
  }
  
  rule {
    source_labels = ["__param_target"]
    target_label  = "instance"
  }
  
  rule {
    target_label = "__address__"
    replacement  = "blackbox-exporter:9115"
  }
  
  rule {
    source_labels = ["__param_target"]
    regex         = "http://([^:]+):.*"
    target_label  = "service"
    replacement   = "$1"
  }
}

prometheus.scrape "blackbox_http_readiness" {
  targets = discovery.relabel.blackbox_readiness.output
  forward_to = [prometheus.relabel.add_job_label_blackbox_readiness.receiver]
  scrape_interval = "15s"
  metrics_path = "/probe"
  params = {
    module = ["http_readiness"],
  }
}

prometheus.relabel "add_job_label_blackbox_readiness" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  
  rule {
    target_label = "job"
    replacement  = "blackbox-http-readiness"
  }
}

// ============================================================================
// REMOTE WRITE TO MIMIR
// ============================================================================

prometheus.remote_write "mimir" {
  endpoint {
    url = "http://mimir:9009/api/v1/push"
    
    headers = {
      "X-Scope-OrgID" = "demo",
    }
    
    queue_config {
      capacity = 10000
      max_shards = 10
      min_shards = 1
      max_samples_per_send = 5000
      batch_send_deadline = "5s"
      min_backoff = "30ms"
      max_backoff = "5s"
    }
    
    write_relabel_config {
      source_labels = ["__name__"]
      regex = "otelcol_.*"
      action = "drop"
    }
    
    write_relabel_config {
      source_labels = ["__name__"]
      regex = ".*\\..*"
      action = "drop"
    }
    
    write_relabel_config {
      regex = "otel\\..*"
      action = "labeldrop"
    }
  }
}

