# TRACES - Há»‡ thá»‘ng Distributed Tracing

## ğŸ¯ Tracing lÃ  gÃ¬ vÃ  Táº¡i sao cáº§n Tracing?

### Äá»‹nh nghÄ©a

**Distributed Tracing** lÃ  ká»¹ thuáº­t theo dÃµi má»™t request khi nÃ³ Ä‘i qua nhiá»u services khÃ¡c nhau trong há»‡ thá»‘ng microservices. Má»—i request Ä‘Æ°á»£c gÃ¡n má»™t **Trace ID** duy nháº¥t, vÃ  má»—i bÆ°á»›c xá»­ lÃ½ trong cÃ¡c services táº¡o ra cÃ¡c **Spans**.

### KhÃ¡i niá»‡m cÆ¡ báº£n

```
Request: GET /api/order/123

Trace ID: abc-def-123
â”‚
â”œâ”€ Span 1: API Gateway (50ms)
â”‚  â”‚
â”‚  â”œâ”€ Span 2: Auth Service (10ms)
â”‚  â”‚
â”‚  â”œâ”€ Span 3: Order Service (35ms)
â”‚     â”‚
â”‚     â”œâ”€ Span 4: Database Query (20ms)
â”‚     â”‚
â”‚     â””â”€ Span 5: Cache Lookup (5ms)
â”‚
â””â”€ Total: 50ms
```

**Trace**: ToÃ n bá»™ journey cá»§a 1 request  
**Span**: 1 Ä‘Æ¡n vá»‹ cÃ´ng viá»‡c trong trace (function call, DB query, HTTP request)  
**Trace ID**: Äá»‹nh danh duy nháº¥t cho trace  
**Span ID**: Äá»‹nh danh duy nháº¥t cho span  
**Parent Span ID**: LiÃªn káº¿t spans thÃ nh cÃ¢y

### Táº¡i sao Tracing quan trá»ng?

#### 1. **Debugging Microservices**

**Váº¥n Ä‘á»**: Request cháº­m, nhÆ°ng khÃ´ng biáº¿t cháº­m á»Ÿ Ä‘Ã¢u?

**KhÃ´ng cÃ³ Tracing:**
```
User: "API /checkout cháº­m quÃ¡!"
Dev: "Hmm... cÃ³ thá»ƒ lÃ :
  - Payment service?
  - Inventory service?
  - Database?
  - Network?
  - ...?"
â†’ Pháº£i check logs tá»«ng service, Ä‘oÃ¡n mÃ²
```

**CÃ³ Tracing:**
```
Trace cho request cháº­m:
â”œâ”€ API Gateway: 2ms âœ…
â”œâ”€ Auth Service: 5ms âœ…
â”œâ”€ Checkout Service: 3ms âœ…
â”œâ”€ Payment Service: 2500ms âŒ â† ÄÃ‚Y Rá»’I!
â”‚  â””â”€ External API call: 2480ms â† Timeout tá»« payment gateway
â””â”€ Inventory Service: 10ms âœ…

â†’ Biáº¿t ngay váº¥n Ä‘á» á»Ÿ Payment Service gá»i external API
```

#### 2. **Performance Optimization**

XÃ¡c Ä‘á»‹nh bottlenecks:
```
Trace: /api/user/profile (total: 450ms)
â”œâ”€ Load user: 50ms
â”œâ”€ Load posts: 200ms â† Cháº­m
â”‚  â”œâ”€ DB query: 180ms â† N+1 query problem
â”‚  â””â”€ Process: 20ms
â”œâ”€ Load friends: 150ms â† Cháº­m
â”‚  â””â”€ DB query: 145ms â† Missing index
â””â”€ Render: 50ms

â†’ Biáº¿t cáº§n optimize 2 queries nÃ y
```

#### 3. **Understanding Dependencies**

Visualize service dependencies:
```
Frontend
   â”‚
   â”œâ”€â”€â–¶ API Gateway
        â”‚
        â”œâ”€â”€â–¶ User Service
        â”‚     â””â”€â”€â–¶ PostgreSQL
        â”‚
        â”œâ”€â”€â–¶ Order Service
        â”‚     â”œâ”€â”€â–¶ MongoDB
        â”‚     â””â”€â”€â–¶ Inventory Service
        â”‚           â””â”€â”€â–¶ Redis
        â”‚
        â””â”€â”€â–¶ Notification Service
              â””â”€â”€â–¶ Email Service (External)
```

#### 4. **Error Correlation**

LiÃªn káº¿t errors qua nhiá»u services:
```
Trace ID: xyz-789
â”œâ”€ Frontend: Error 500
â”œâ”€ API Gateway: Passed through
â”œâ”€ Order Service: Exception thrown
â”‚  â””â”€ Error: "Inventory not available"
â””â”€ Inventory Service: Database connection timeout
   â””â”€ Root cause: PostgreSQL down

â†’ Biáº¿t error 500 á»Ÿ frontend thá»±c ra do PostgreSQL down
```

## ğŸ—ï¸ Kiáº¿n trÃºc Tracing trong Há»‡ thá»‘ng

## ğŸ—ï¸ Kiáº¿n trÃºc Tracing trong Há»‡ thá»‘ng

```mermaid
graph TB
    classDef app fill:#e1f5ff,stroke:#0277bd,stroke-width:2px,rx:5,ry:5
    classDef agent fill:#fff9c4,stroke:#fbc02d,stroke-width:2px,rx:5,ry:5
    classDef component fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,rx:3,ry:3
    classDef storage fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,rx:5,ry:5

    subgraph "Application Layer"
        APP[Applications<br/>NestJS, Go, Python...]:::app
    end
    
    subgraph "Grafana Alloy (Unified Agent)"
        OTLP_RECV[OTLP Receiver<br/>otelcol.receiver.otlp]:::component
        PROCESS[Processors<br/>Memory Limiter, Batch]:::component
        EXPORTER[Exporters<br/>otelcol.exporter.otlp]:::component
    end
    
    subgraph "Storage"
        TEMPO[Tempo<br/>Trace Storage]:::storage
    end
    
    APP -->|OTLP gRPC :4317| OTLP_RECV
    APP -->|OTLP HTTP :4318| OTLP_RECV
    
    OTLP_RECV --> PROCESS
    PROCESS --> EXPORTER
    EXPORTER -->|OTLP gRPC| TEMPO
    
    style OTLP_RECV fill:#fff3e0
    style PROCESS fill:#fff3e0
    style EXPORTER fill:#fff3e0
```

## ğŸ”§ Cáº¥u hÃ¬nh Grafana Alloy cho Traces

**Grafana Alloy** thay tháº¿ OpenTelemetry Collector Ä‘á»ƒ thu tháº­p, xá»­ lÃ½ vÃ  forward traces. Cáº¥u hÃ¬nh náº±m trong file `alloy/config.alloy`.

### 1. Unified Telemetry Flow

KhÃ¡c vá»›i OTEL Collector (YAML), Alloy sá»­ dá»¥ng cÃ¡c **component blocks** Ä‘á»ƒ Ä‘á»‹nh nghÄ©a pipeline:

```alloy
// 1. Nháº­n Traces tá»« Applications (OTLP Receiver)
otelcol.receiver.otlp "default" {
  grpc {
    endpoint = "0.0.0.0:4317" // Nháº­n gRPC traces
  }

  http {
    endpoint = "0.0.0.0:4318" // Nháº­n HTTP traces
  }

  output {
    // Send to processing pipeline
    metrics = [otelcol.processor.memory_limiter.default.input]
    traces  = [otelcol.processor.memory_limiter.default.input]
    logs    = [otelcol.processor.memory_limiter.default.input]
  }
}
```

### 2. Processing Pipeline

```alloy
// 2. Báº£o vá»‡ memory (Memory Limiter)
otelcol.processor.memory_limiter "default" {
  check_interval = "1s"
  limit          = "400MiB"
  spike_limit    = "100MiB"

  output {
    metrics = [otelcol.processor.batch.default.input]
    traces  = [otelcol.processor.batch.default.input]
    logs    = [otelcol.processor.batch.default.input]
  }
}

// 3. Tá»‘i Æ°u network (Batch Processor)
otelcol.processor.batch "default" {
  timeout             = "5s"
  send_batch_size     = 8192
  send_batch_max_size = 10000

  output {
    // Fan-out Ä‘áº¿n cÃ¡c exporters
    metrics = [otelcol.exporter.prometheus.otlp_metrics.input]
    traces  = [otelcol.exporter.otlp.tempo.input]
    logs    = [otelcol.exporter.loki.otlp_logs.input]
  }
}
```

### 3. Export to Tempo

```alloy
// 4. Gá»­i Traces Ä‘áº¿n Tempo
otelcol.exporter.otlp "tempo" {
  client {
    endpoint = "tempo:4317"
    tls {
      insecure = true
    }
  }
}
```

### So sÃ¡nh OTEL Collector vs Alloy

| Feature | OTEL Collector (YAML) | Alloy (Block Syntax) |
|---------|-----------------------|----------------------|
| **Pipeline** | `receivers` -> `processors` -> `exporters` | Components connected by `input`/`output` |
| **Integrations** | Cáº§n enable receiver tÆ°Æ¡ng á»©ng | Native support cho Docker, File, System |
| **Config** | Static YAML | Dynamic, Scriptable |

### 2. Tempo - Trace Storage Backend

**Tempo** lÃ  distributed tracing backend cá»§a Grafana Labs, tá»‘i Æ°u cho cost-effective storage.

#### Äáº·c Ä‘iá»ƒm

**1. Write Path:**
```
Collector â”€â”€â–¶ Distributor â”€â”€â–¶ Ingester â”€â”€â–¶ Storage
                                â”‚
                                â””â”€â”€â–¶ WAL (Write-Ahead Log)
```

- **Distributor**: Nháº­n traces, hash trace_id Ä‘á»ƒ route Ä‘áº¿n ingester
- **Ingester**: Buffer traces trong memory, flush Ä‘á»‹nh ká»³
- **WAL**: Durability, trÃ¡nh máº¥t data náº¿u crash

**2. Storage:**

```yaml
storage:
  trace:
    backend: local
    local:
      path: /var/tempo/traces
    wal:
      path: /var/tempo/wal
```

**Backend options:**
- **local**: Filesystem (development/small scale)
- **s3**: AWS S3 (production)
- **gcs**: Google Cloud Storage
- **azure**: Azure Blob Storage

**Táº¡i sao dÃ¹ng object storage (S3/GCS)?**
- **Cost**: $0.023/GB/month (S3) vs $0.10/GB/month (EBS)
- **Scalability**: Unlimited storage
- **Durability**: 99.999999999% (11 nines)

**3. Compaction:**

```yaml
compactor:
  compaction:
    block_retention: 168h  # 7 days
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**
```
Ingester táº¡o blocks má»—i 5 phÃºt:
block-001 (0-5min)
block-002 (5-10min)
block-003 (10-15min)
...

Compactor gá»™p blocks:
block-001 + block-002 + ... + block-12 â†’ block-hour-1 (0-60min)
block-hour-1 + ... + block-hour-24 â†’ block-day-1 (0-24h)

XÃ³a blocks cÅ© hÆ¡n 168h
```

**Lá»£i Ã­ch:**
- Giáº£m sá»‘ lÆ°á»£ng files
- Query nhanh hÆ¡n (Ã­t files pháº£i scan)
- Tiáº¿t kiá»‡m storage (compression tá»‘t hÆ¡n)

#### Metrics Generator

**TÃ­nh nÄƒng Ä‘áº·c biá»‡t**: Tempo cÃ³ thá»ƒ generate metrics tá»« traces!

```yaml
metrics_generator:
  registry:
    external_labels:
      source: tempo
      cluster: docker-compose
    collection_interval: 15s
  storage:
    path: /var/tempo/generator/wal
    remote_write:
      - url: http://prometheus:9090/api/v1/write
        send_exemplars: true
```

**Processor types:**

**1. Service Graphs**

```yaml
processor:
  service_graphs:
    max_items: 10000
```

**Output**: Metrics vá» service-to-service calls

```promql
# Request rate giá»¯a services
traces_service_graph_request_total{client="frontend", server="api-gateway"} 1000

# Latency
traces_service_graph_request_duration_seconds{client="frontend", server="api-gateway"} 0.05

# Failed requests
traces_service_graph_request_failed_total{client="frontend", server="api-gateway"} 10
```

**Sá»­ dá»¥ng**: Váº½ service dependency graph trong Grafana

**2. Span Metrics**

```yaml
processor:
  span_metrics:
    dimensions:
      - http.method
      - http.target
      - http.status_code
      - service.version
```

**Output**: Metrics tá»« span attributes

```promql
# Request duration by endpoint
traces_span_metrics_duration_seconds{http_method="GET", http_target="/api/users", http_status_code="200"}

# Request count
traces_span_metrics_calls_total{http_method="POST", http_target="/api/orders"}
```

**3. Exemplars**

**Exemplars** = Link tá»« metric data point Ä‘áº¿n trace cá»¥ thá»ƒ.

```
Metric: http_request_duration_seconds
Value: 0.5s at timestamp 1735574400

Exemplar: {
  value: 0.5
  timestamp: 1735574400
  trace_id: "abc123..."  â† Link to trace
  span_id: "def456..."
}
```

**Workflow trong Grafana:**
```
1. Xem metric graph: Response time tÄƒng Ä‘á»™t ngá»™t
2. Click vÃ o spike point
3. Grafana hiá»ƒn thá»‹ exemplar traces
4. Click vÃ o trace â†’ Xem chi tiáº¿t trace
5. Debug táº¡i sao request nÃ y cháº­m
```

**Lá»£i Ã­ch:**
- Jump tá»« "cÃ³ váº¥n Ä‘á»" (metrics) â†’ "váº¥n Ä‘á» cá»¥ thá»ƒ lÃ  gÃ¬" (trace)
- KhÃ´ng cáº§n search trace ID manually

### 4. Trace Query vÃ  Visualization

#### Query Traces trong Grafana

**1. Trace ID Search:**
```
Trace ID: abc-def-123
â†’ Hiá»ƒn thá»‹ toÃ n bá»™ trace vá»›i táº¥t cáº£ spans
```

**2. TraceQL (Trace Query Language):**

```traceql
# TÃ¬m traces cháº­m
{ duration > 1s }

# Traces cÃ³ errors
{ status = error }

# Traces tá»« service cá»¥ thá»ƒ
{ service.name = "api-gateway" }

# Traces vá»›i HTTP 500
{ span.http.status_code = 500 }

# Complex query
{
  service.name = "order-service" &&
  duration > 500ms &&
  span.http.method = "POST"
}
```

**3. Metrics to Traces:**

```
Prometheus query: rate(http_requests_total[5m])
â†’ Click vÃ o data point
â†’ Grafana tÃ¬m exemplar trace
â†’ Jump to trace view
```

#### Trace Visualization

**Waterfall View:**
```
Trace: GET /api/order/123 (total: 450ms)
â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Timeline
â”‚
â”œâ”€ API Gateway                    [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 50ms
â”‚  â”‚
â”‚  â”œâ”€ Auth Service                [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 10ms
â”‚  â”‚
â”‚  â””â”€ Order Service               [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 350ms
â”‚     â”‚
â”‚     â”œâ”€ Validate Order           [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 20ms
â”‚     â”‚
â”‚     â”œâ”€ Check Inventory          [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 50ms
â”‚     â”‚  â”‚
â”‚     â”‚  â””â”€ Redis GET             [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 5ms
â”‚     â”‚
â”‚     â”œâ”€ Process Payment          [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 250ms â† Bottleneck!
â”‚     â”‚  â”‚
â”‚     â”‚  â””â”€ External Payment API  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 240ms
â”‚     â”‚
â”‚     â””â”€ Save to DB               [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 30ms
â”‚        â”‚
â”‚        â””â”€ PostgreSQL INSERT     [â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 25ms
â”‚
â””â”€ Response                       [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0ms
```

**Span Details:**
```
Span: Process Payment
â”œâ”€ Duration: 250ms
â”œâ”€ Status: OK
â”œâ”€ Attributes:
â”‚  â”œâ”€ payment.method: "credit_card"
â”‚  â”œâ”€ payment.amount: 99.99
â”‚  â”œâ”€ payment.currency: "USD"
â”‚  â””â”€ payment.gateway: "stripe"
â”œâ”€ Events:
â”‚  â”œâ”€ [10ms] Payment request sent
â”‚  â”œâ”€ [240ms] Payment response received
â”‚  â””â”€ [250ms] Payment confirmed
â””â”€ Links:
   â””â”€ Related trace: order-confirmation-email
```

**Service Graph:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ 1000 req/s
     â”‚ 50ms avg
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Gateway  â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
   â”‚        â”‚
   â”‚        â”‚ 800 req/s
   â”‚        â”‚ 100ms avg
   â”‚        â–¼
   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   â”‚   Auth     â”‚
   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ 1000 req/s
   â”‚ 200ms avg
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Order Service â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
   â”‚        â”‚
   â”‚        â”‚ 500 req/s
   â”‚        â”‚ 50ms avg
   â”‚        â–¼
   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   â”‚ Inventory  â”‚
   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ 1000 req/s
   â”‚ 150ms avg
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Payment    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Instrumentation Best Practices

### 1. Span Naming

**Good:**
```
GET /api/users
POST /api/orders
SELECT users WHERE id = ?
Redis GET user:123
```

**Bad:**
```
handleRequest
doWork
query
fetch
```

**Principles:**
- Descriptive: Biáº¿t span lÃ m gÃ¬
- Consistent: CÃ¹ng format trong toÃ n bá»™ há»‡ thá»‘ng
- Low cardinality: KhÃ´ng include IDs, user-specific data

### 2. Span Attributes

**Good:**
```javascript
span.setAttribute("http.method", "GET")
span.setAttribute("http.url", "/api/users")
span.setAttribute("http.status_code", 200)
span.setAttribute("db.system", "postgresql")
span.setAttribute("db.statement", "SELECT * FROM users WHERE id = ?")
```

**Bad:**
```javascript
span.setAttribute("user_id", "12345")  // High cardinality
span.setAttribute("request_body", "{...}")  // Too large
span.setAttribute("password", "secret")  // Sensitive data
```

**Semantic Conventions**: Sá»­ dá»¥ng standard attributes tá»« OpenTelemetry
- `http.*`: HTTP requests
- `db.*`: Database operations
- `messaging.*`: Message queues
- `rpc.*`: RPC calls

### 3. Span Events

**Sá»­ dá»¥ng events cho Ä‘iá»ƒm quan trá»ng trong span:**

```javascript
span.addEvent("cache_miss", {
  "cache.key": "user:123",
  "cache.ttl": 3600
})

span.addEvent("validation_failed", {
  "validation.field": "email",
  "validation.error": "invalid format"
})

span.addEvent("retry_attempt", {
  "retry.count": 2,
  "retry.max": 3
})
```

### 4. Error Handling

```javascript
try {
  // Do work
  span.setStatus({ code: SpanStatusCode.OK })
} catch (error) {
  span.setStatus({
    code: SpanStatusCode.ERROR,
    message: error.message
  })
  span.recordException(error)
  throw error
}
```

### 5. Sampling

**Váº¥n Ä‘á»**: 100% traces = quÃ¡ nhiá»u data, tá»‘n storage, tá»‘n tiá»n.

**Giáº£i phÃ¡p**: Sampling - chá»‰ giá»¯ má»™t pháº§n traces.

**Sampling strategies:**

**1. Head-based Sampling** (quyáº¿t Ä‘á»‹nh á»Ÿ Ä‘áº§u trace):
```
Random: 10% of all traces
Rate limiting: Max 100 traces/second
```

**2. Tail-based Sampling** (quyáº¿t Ä‘á»‹nh sau khi trace hoÃ n thÃ nh):
```
Keep if:
  - Duration > 1s
  - Has errors
  - Status code 5xx
  - Random 1% of normal requests
```

**Cáº¥u hÃ¬nh trong Collector:**
```yaml
processors:
  probabilistic_sampler:
    sampling_percentage: 10  # Keep 10%
  
  tail_sampling:
    policies:
      - name: errors
        type: status_code
        status_code: {status_codes: [ERROR]}
      - name: slow
        type: latency
        latency: {threshold_ms: 1000}
      - name: random
        type: probabilistic
        probabilistic: {sampling_percentage: 1}
```

## ğŸ’¡ Use Cases

### 1. Debugging Slow Requests

**Scenario**: API `/api/dashboard` Ä‘Ã´i khi cháº­m.

**BÆ°á»›c 1**: Query slow traces
```traceql
{
  span.http.target = "/api/dashboard" &&
  duration > 2s
}
```

**BÆ°á»›c 2**: PhÃ¢n tÃ­ch waterfall
```
Trace 1: 3.5s total
â”œâ”€ Load user: 50ms
â”œâ”€ Load widgets: 3.2s â† Bottleneck
â”‚  â””â”€ DB query: 3.1s â† N+1 query
â””â”€ Render: 200ms
```

**BÆ°á»›c 3**: Fix N+1 query, verify
```
Trace 2 (after fix): 400ms total
â”œâ”€ Load user: 50ms
â”œâ”€ Load widgets: 150ms â† Fixed!
â”‚  â””â”€ DB query: 100ms
â””â”€ Render: 200ms
```

### 2. Finding Error Root Cause

**Scenario**: User bÃ¡o lá»—i 500.

**BÆ°á»›c 1**: TÃ¬m trace vá»›i error
```traceql
{
  span.http.status_code = 500 &&
  service.name = "api-gateway"
}
```

**BÆ°á»›c 2**: Follow trace tree
```
API Gateway: 500 â† User tháº¥y
â””â”€ Order Service: Exception
   â””â”€ Payment Service: Timeout
      â””â”€ External API: Connection refused
         â†’ Root cause: Payment gateway down
```

### 3. Capacity Planning

**Query service graph metrics:**
```promql
# Request rate trend
rate(traces_service_graph_request_total[1h])

# P95 latency trend
histogram_quantile(0.95, 
  rate(traces_service_graph_request_duration_seconds_bucket[5m])
)
```

**Insight:**
- Order Service: 1000 req/s hiá»‡n táº¡i
- TÄƒng 20%/thÃ¡ng
- P95 latency: 200ms (gáº§n limit 250ms)
â†’ Cáº§n scale trong 2 thÃ¡ng

## ğŸ“ Tá»•ng káº¿t

### Tracing Flow Summary

1. **Application** instrument vá»›i OpenTelemetry SDK
2. **Spans** Ä‘Æ°á»£c táº¡o cho má»—i operation
3. **OTLP** gá»­i spans Ä‘áº¿n OpenTelemetry Collector
4. **Collector** process (batch, sample) vÃ  export
5. **Tempo** lÆ°u trá»¯ traces
6. **Metrics Generator** táº¡o metrics tá»« spans â†’ Prometheus
7. **Grafana** query vÃ  visualize traces

### Key Takeaways

âœ… **Tracing = Following requests through microservices**  
âœ… **Trace = Collection of spans vá»›i cÃ¹ng trace_id**  
âœ… **OpenTelemetry = Vendor-neutral instrumentation standard**  
âœ… **Collector = Central pipeline cho telemetry data**  
âœ… **Tempo = Cost-effective trace storage**  
âœ… **Exemplars = Bridge tá»« metrics â†’ traces**  

### Khi nÃ o dÃ¹ng Tracing?

- âœ… Debug microservices (request Ä‘i qua nhiá»u services)
- âœ… TÃ¬m performance bottlenecks
- âœ… Understand service dependencies
- âœ… Root cause analysis cho errors
- âœ… Latency breakdown (thá»i gian á»Ÿ Ä‘Ã¢u?)
- âŒ System-wide trends (dÃ¹ng Metrics)
- âŒ Detailed logs (dÃ¹ng Logs)
- âŒ Audit trail (dÃ¹ng Logs)
