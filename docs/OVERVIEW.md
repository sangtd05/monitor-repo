# MONITORING SYSTEM OVERVIEW

## üéØ Gi·ªõi thi·ªáu

H·ªá th·ªëng monitoring n√†y ƒë∆∞·ª£c x√¢y d·ª±ng d·ª±a tr√™n **LGTM Stack** (Loki, Grafana, Tempo, Mimir/Prometheus) - m·ªôt gi·∫£i ph√°p observability to√†n di·ªán cho vi·ªác gi√°m s√°t ·ª©ng d·ª•ng v√† h·∫° t·∫ßng.

### Observability l√† g√¨?

**Observability** (kh·∫£ nƒÉng quan s√°t) l√† kh·∫£ nƒÉng hi·ªÉu ƒë∆∞·ª£c tr·∫°ng th√°i n·ªôi b·ªô c·ªßa h·ªá th·ªëng th√¥ng qua c√°c outputs m√† n√≥ t·∫°o ra. Kh√°c v·ªõi monitoring truy·ªÅn th·ªëng (ch·ªâ bi·∫øt "c√≥ v·∫•n ƒë·ªÅ"), observability gi√∫p b·∫°n **hi·ªÉu t·∫°i sao** c√≥ v·∫•n ƒë·ªÅ.

### Ba Tr·ª• c·ªôt c·ªßa Observability

```mermaid
graph TB
    O[Observability]
    
    O --> M[METRICS<br/>What is happening?<br/>S·ªë ƒëo theo th·ªùi gian]
    O --> T[TRACES<br/>Where is the problem?<br/>Request journey]
    O --> L[LOGS<br/>Why did it happen?<br/>Event details]
    
    M -.->|Spike detected| T
    T -.->|Find bottleneck| L
    L -.->|Root cause| M
    
    style M fill:#ff9999
    style T fill:#cc99ff
    style L fill:#99ccff
```

#### 1. **METRICS** - "H·ªá th·ªëng ƒëang th·∫ø n√†o?"

**ƒê·ªãnh nghƒ©a:** S·ªë ƒëo ƒë·ªãnh l∆∞·ª£ng theo th·ªùi gian (time-series data).

**V√≠ d·ª•:**
- CPU usage: 75%
- Request rate: 1000 req/s
- Error rate: 2%
- Response time: 150ms (p95)

**Khi n√†o d√πng:**
- ‚úÖ Ph√°t hi·ªán v·∫•n ƒë·ªÅ s·ªõm (CPU tƒÉng d·∫ßn)
- ‚úÖ Alerting (error rate > 5%)
- ‚úÖ Capacity planning (traffic tƒÉng 20%/th√°ng)
- ‚úÖ SLA monitoring (99.9% uptime)

**C√¥ng c·ª•:** Prometheus + Grafana

---

#### 2. **TRACES** - "Request ƒëi ƒë√¢u v√† m·∫•t bao l√¢u?"

**ƒê·ªãnh nghƒ©a:** Theo d√µi m·ªôt request khi n√≥ ƒëi qua nhi·ªÅu services.

**V√≠ d·ª•:**
```
Request: GET /api/order/123 (total: 450ms)
‚îú‚îÄ API Gateway: 50ms
‚îú‚îÄ Auth Service: 10ms
‚îî‚îÄ Order Service: 350ms
   ‚îú‚îÄ Database: 30ms
   ‚îî‚îÄ Payment API: 250ms ‚Üê Bottleneck!
```

**Khi n√†o d√πng:**
- ‚úÖ Debug microservices (request ch·∫≠m ·ªü ƒë√¢u?)
- ‚úÖ Performance optimization (t√¨m bottlenecks)
- ‚úÖ Hi·ªÉu service dependencies
- ‚úÖ Latency breakdown

**C√¥ng c·ª•:** OpenTelemetry + Tempo + Grafana

---

#### 3. **LOGS** - "Chuy·ªán g√¨ ƒë√£ x·∫£y ra?"

**ƒê·ªãnh nghƒ©a:** B·∫£n ghi chi ti·∫øt v·ªÅ c√°c s·ª± ki·ªán trong h·ªá th·ªëng.

**V√≠ d·ª•:**
```json
{
  "timestamp": "2025-12-30T15:30:45Z",
  "level": "ERROR",
  "message": "Payment failed",
  "userId": 123,
  "orderId": "abc-123",
  "error": "Card declined",
  "trace_id": "xyz-789"
}
```

**Khi n√†o d√πng:**
- ‚úÖ Debugging chi ti·∫øt (stack traces)
- ‚úÖ Audit trail (ai l√†m g√¨, khi n√†o)
- ‚úÖ Security investigations
- ‚úÖ Business analytics

**C√¥ng c·ª•:** Loki + Promtail + Grafana

---

### Workflow ƒêi·ªÉn h√¨nh: Metrics ‚Üí Traces ‚Üí Logs

```mermaid
sequenceDiagram
    participant Dev as Developer
    participant M as Metrics (Prometheus)
    participant T as Traces (Tempo)
    participant L as Logs (Loki)
    
    Note over Dev: User b√°o: "API ch·∫≠m!"
    
    Dev->>M: Check metrics
    M-->>Dev: Response time p95: 2s<br/>(spike at 15:30)
    
    Note over Dev: Bi·∫øt C√ì v·∫•n ƒë·ªÅ, KH√îNG bi·∫øt t·∫°i sao
    
    Dev->>M: Click exemplar trace
    M->>T: Jump to trace
    T-->>Dev: Trace breakdown:<br/>Payment Service: 1.8s
    
    Note over Dev: Bi·∫øt v·∫•n ƒë·ªÅ ·ªû ƒê√ÇU
    
    Dev->>T: Click Payment Service span
    T->>L: Jump to logs (trace_id)
    L-->>Dev: ERROR: External API timeout<br/>after 1.8s
    
    Note over Dev: Bi·∫øt T·∫†I SAO: External API down
```

**K·ªãch b·∫£n th·ª±c t·∫ø:**

1. **Grafana dashboard** hi·ªÉn th·ªã spike ·ªü response time (Metrics)
2. Click v√†o spike ‚Üí Xem **exemplar traces** (Traces)
3. Trace cho th·∫•y Payment Service ch·∫≠m
4. Click v√†o span ‚Üí Xem **logs** v·ªõi c√πng trace_id (Logs)
5. Logs cho th·∫•y: External payment API timeout
6. **Root cause:** Payment gateway ƒëang down

---

## üèóÔ∏è Ki·∫øn tr√∫c T·ªïng quan

```mermaid
graph TB
    subgraph "Data Sources"
        APP[Applications<br/>NestJS Backend]
        DB[(Databases<br/>PostgreSQL, MongoDB)]
        SYS[Infrastructure<br/>Servers, Containers]
    end
    
    subgraph "Collection Layer"
        subgraph "Metrics Collection"
            EXP[Exporters<br/>DB Exporters<br/>Node Exporter<br/>cAdvisor]
            PROM_S[Prometheus<br/>Scraper]
        end
        
        subgraph "Traces Collection"
            OTEL[OpenTelemetry<br/>Collector<br/>:4317/:4318]
        end
        
        subgraph "Logs Collection"
            PROMTAIL[Promtail<br/>File Scraper]
            PINO[Pino-Loki<br/>Direct Push]
        end
    end
    
    subgraph "Storage Layer"
        PROM_DB[(Prometheus<br/>TSDB<br/>15d retention)]
        TEMPO_DB[(Tempo<br/>Traces<br/>7d retention)]
        LOKI_DB[(Loki<br/>Logs<br/>7d retention)]
    end
    
    subgraph "Visualization & Alerting"
        GRAFANA[Grafana<br/>:3000<br/>Unified UI]
        ALERT[Alertmanager<br/>:9093<br/>Telegram]
    end
    
    APP -->|Traces OTLP| OTEL
    APP -->|Logs HTTP| PINO
    APP -->|Metrics| EXP
    
    DB -->|Logs| PROMTAIL
    DB -->|Metrics| EXP
    
    SYS -->|Logs| PROMTAIL
    SYS -->|Metrics| EXP
    
    EXP --> PROM_S
    PROM_S --> PROM_DB
    
    OTEL --> TEMPO_DB
    OTEL -->|Span Metrics| PROM_DB
    
    PROMTAIL --> LOKI_DB
    PINO --> LOKI_DB
    
    PROM_DB --> GRAFANA
    TEMPO_DB --> GRAFANA
    LOKI_DB --> GRAFANA
    
    PROM_DB --> ALERT
    LOKI_DB --> ALERT
    
    style APP fill:#99ccff
    style GRAFANA fill:#99ff99
    style PROM_DB fill:#ff9999
    style TEMPO_DB fill:#cc99ff
    style LOKI_DB fill:#ffcc99
```

---

## üìÅ C·∫•u tr√∫c Repository

```
monitor-repo/
‚îú‚îÄ‚îÄ grafana-prometheus/          # LGTM Stack ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/              # Metrics storage & alerting
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml       # Scrape configs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rules.alert.yml      # System alerts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rules.postgres.yml   # PostgreSQL alerts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rules.mongodb.yml    # MongoDB alerts
‚îÇ   ‚îú‚îÄ‚îÄ loki/                    # Logs storage
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ loki-config.yml      # Retention, limits
‚îÇ   ‚îú‚îÄ‚îÄ tempo/                   # Traces storage
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tempo-config.yml     # Retention, metrics generator
‚îÇ   ‚îú‚îÄ‚îÄ otel-collector/          # Traces collection
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ otel-collector-config.yml
‚îÇ   ‚îú‚îÄ‚îÄ promtail/                # Logs collection
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ promtail-config.yml  # Docker, system, exporters
‚îÇ   ‚îú‚îÄ‚îÄ grafana/                 # Visualization
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ provisioning/        # Datasources, dashboards
‚îÇ   ‚îú‚îÄ‚îÄ alertmanager/            # Alert routing
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml       # Full stack
‚îÇ
‚îú‚îÄ‚îÄ db/                          # Database test environment
‚îÇ   ‚îú‚îÄ‚îÄ postgres/                # PostgreSQL config
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ postgresql.conf      # Logging: ALL statements
‚îÇ   ‚îú‚îÄ‚îÄ mongodb/                 # MongoDB config
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mongod.conf          # Profiling: 100%
‚îÇ   ‚îú‚îÄ‚îÄ promtail/                # DB logs collector
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ promtail-config.yml  # Parse PG & Mongo logs
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml       # PG, Mongo, Exporters, Promtail
‚îÇ
‚îú‚îÄ‚îÄ aisoft-backend/              # NestJS application
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ common/logger/       # Pino logger service
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config/logger.config.ts
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml       # App + dependencies
‚îÇ
‚îî‚îÄ‚îÄ Documentation/               # T√†i li·ªáu n√†y
    ‚îú‚îÄ‚îÄ OVERVIEW.md              # ‚Üê B·∫°n ƒëang ƒë·ªçc
    ‚îú‚îÄ‚îÄ METRICS.md               # Chi ti·∫øt v·ªÅ Metrics
    ‚îú‚îÄ‚îÄ TRACES.md                # Chi ti·∫øt v·ªÅ Traces
    ‚îú‚îÄ‚îÄ LOGS.md                  # Chi ti·∫øt v·ªÅ Logs
    ‚îú‚îÄ‚îÄ DATABASE-MONITORING.md   # Chi ti·∫øt v·ªÅ DB monitoring
    ‚îú‚îÄ‚îÄ APPLICATION-LOGGING.md   # Chi ti·∫øt v·ªÅ App logging
    ‚îî‚îÄ‚îÄ DIAGRAMS.md              # Mermaid diagrams
```

---

## üîß C√°c Th√†nh ph·∫ßn Ch√≠nh

### 1. Prometheus - Metrics Storage

**Vai tr√≤:** Thu th·∫≠p v√† l∆∞u tr·ªØ metrics t·ª´ c√°c targets.

**C√°ch ho·∫°t ƒë·ªông:**
- **Pull model:** Prometheus scrape metrics t·ª´ exporters m·ªói 15s
- **TSDB:** Time-series database t·ªëi ∆∞u cho metrics
- **PromQL:** Query language m·∫°nh m·∫Ω
- **Alerting:** ƒê√°nh gi√° alert rules v√† g·ª≠i ƒë·∫øn Alertmanager

**Targets:**
- Prometheus itself (self-monitoring)
- Alertmanager
- OTEL Collector
- Promtail, Loki, Tempo
- Node Exporter (system metrics)
- cAdvisor (container metrics)
- PostgreSQL Exporter
- MongoDB Exporter

**Port:** 9090

**T√†i li·ªáu:** [METRICS.md](./METRICS.md)

---

### 2. Loki - Logs Aggregation

**Vai tr√≤:** Thu th·∫≠p, l∆∞u tr·ªØ v√† query logs.

**C√°ch ho·∫°t ƒë·ªông:**
- **Label-based indexing:** Ch·ªâ index labels, kh√¥ng index log content
- **Cost-effective:** Storage nh·ªè h∆°n Elasticsearch 10-100x
- **LogQL:** Query language gi·ªëng PromQL

**Log sources:**
- **Promtail:** Scrape logs t·ª´ files (Docker, system, databases)
- **Pino-Loki:** Push logs tr·ª±c ti·∫øp t·ª´ application

**Retention:** 7 days (configurable)

**Port:** 3100

**T√†i li·ªáu:** [LOGS.md](./LOGS.md)

---

### 3. Tempo - Distributed Tracing

**Vai tr√≤:** L∆∞u tr·ªØ v√† query distributed traces.

**C√°ch ho·∫°t ƒë·ªông:**
- **OTLP receiver:** Nh·∫≠n traces t·ª´ OpenTelemetry
- **Trace storage:** Local filesystem ho·∫∑c object storage (S3, GCS)
- **Metrics generator:** T·∫°o metrics t·ª´ spans (service graphs, span metrics)
- **Exemplars:** Link t·ª´ metrics ‚Üí traces

**Retention:** 7 days (168h)

**Port:** 3200

**T√†i li·ªáu:** [TRACES.md](./TRACES.md)

---

### 4. OpenTelemetry Collector - Telemetry Pipeline

**Vai tr√≤:** Nh·∫≠n, x·ª≠ l√Ω, v√† export telemetry data (traces, metrics, logs).

**Pipeline:**
```
Receivers ‚Üí Processors ‚Üí Exporters
   ‚Üì            ‚Üì            ‚Üì
  OTLP      Batch        Tempo
            Memory       Prometheus
            Limiter
```

**Processors:**
- **Batch:** G·ªôp data th√†nh batches (hi·ªáu qu·∫£ network)
- **Memory Limiter:** Tr√°nh OOM khi traffic spike

**Ports:**
- 4317: OTLP gRPC
- 4318: OTLP HTTP
- 8889: Prometheus metrics endpoint

**T√†i li·ªáu:** [TRACES.md](./TRACES.md)

---

### 5. Promtail - Log Collector

**Vai tr√≤:** Thu th·∫≠p logs t·ª´ files v√† g·ª≠i ƒë·∫øn Loki.

**Jobs:**
- **docker:** Docker container logs (service discovery)
- **system:** System logs (`/var/log`)
- **exporters:** Logs t·ª´ exporters

**Pipeline stages:**
1. **Multiline:** Combine SQL queries
2. **Regex/JSON:** Parse log format
3. **Labels:** Extract labels
4. **Timestamp:** Parse timestamp
5. **Drop:** Filter unwanted logs

**Port:** 9080 (metrics)

**T√†i li·ªáu:** [LOGS.md](./LOGS.md)

---

### 6. Grafana - Unified Visualization

**Vai tr√≤:** Visualization v√† exploration platform.

**Datasources:**
- Prometheus (metrics)
- Loki (logs)
- Tempo (traces)

**Features:**
- **Dashboards:** Pre-built v√† custom dashboards
- **Explore:** Ad-hoc querying
- **Alerting:** Alert rules v√† notifications
- **Correlations:** Jump t·ª´ metrics ‚Üí traces ‚Üí logs

**Port:** 3000

**T√†i li·ªáu:** T·∫•t c·∫£ c√°c file .md

---

### 7. Alertmanager - Alert Routing

**Vai tr√≤:** Nh·∫≠n alerts t·ª´ Prometheus/Loki, group, v√† route ƒë·∫øn receivers.

**Features:**
- **Grouping:** G·ªôp alerts c√πng lo·∫°i
- **Inhibition:** Suppress alerts ph·ª• thu·ªôc
- **Silencing:** T·∫Øt alerts t·∫°m th·ªùi
- **Routing:** G·ª≠i ƒë·∫øn ƒë√∫ng channel (Telegram, Email, Slack)

**Port:** 9093

**T√†i li·ªáu:** [METRICS.md](./METRICS.md)

---

## üéØ Use Cases Th·ª±c t·∫ø

### Use Case 1: Debug Slow API

**V·∫•n ƒë·ªÅ:** API `/api/dashboard` ƒë√¥i khi ch·∫≠m (> 2s).

**Workflow:**

1. **Metrics (Prometheus):**
   ```promql
   histogram_quantile(0.95, 
     rate(http_request_duration_seconds_bucket{endpoint="/api/dashboard"}[5m])
   )
   ```
   ‚Üí Th·∫•y p95 latency = 2.5s

2. **Traces (Tempo):**
   - Click exemplar trace t·ª´ metric spike
   - Xem trace breakdown:
     ```
     Total: 2.5s
     ‚îú‚îÄ Load user: 50ms
     ‚îú‚îÄ Load widgets: 2.2s ‚Üê Bottleneck
     ‚îî‚îÄ Render: 250ms
     ```

3. **Logs (Loki):**
   ```logql
   {service="api"} | json | trace_id="abc-123"
   ```
   ‚Üí Th·∫•y: N+1 query problem trong `load widgets`

4. **Fix:** Optimize query v·ªõi JOIN

5. **Verify:**
   - Metrics: p95 latency gi·∫£m xu·ªëng 400ms
   - Traces: Load widgets ch·ªâ c√≤n 150ms

---

### Use Case 2: Database Performance

**V·∫•n ƒë·ªÅ:** PostgreSQL slow queries.

**Workflow:**

1. **Metrics:**
   ```promql
   pg_stat_activity_max_tx_duration{state="active"} > 300
   ```
   ‚Üí Alert: Query ch·∫°y > 5 ph√∫t

2. **Logs:**
   ```logql
   {service="postgresql"} |= "duration:" | regexp "duration: (?P<duration>\\d+) ms" | duration > 5000
   ```
   ‚Üí Th·∫•y query c·ª• th·ªÉ:
   ```sql
   SELECT * FROM orders WHERE user_id IN (...)
   -- 50,000 rows scanned
   ```

3. **Metrics (Table stats):**
   ```promql
   pg_stat_user_tables_seq_scan{relname="orders"} 
   / 
   (pg_stat_user_tables_seq_scan + pg_stat_user_tables_idx_scan)
   ```
   ‚Üí Sequential scan ratio = 0.8 (80% seq scans)

4. **Fix:** Th√™m index tr√™n `user_id`

5. **Verify:**
   - Metrics: Seq scan ratio gi·∫£m xu·ªëng 0.1
   - Logs: Query duration < 100ms

---

### Use Case 3: Application Error Spike

**V·∫•n ƒë·ªÅ:** Error rate tƒÉng ƒë·ªôt ng·ªôt.

**Workflow:**

1. **Metrics:**
   ```promql
   rate(http_requests_total{status=~"5.."}[5m])
   ```
   ‚Üí 50 errors/second (b√¨nh th∆∞·ªùng: 1/second)

2. **Logs (Error messages):**
   ```logql
   {service="api", level="error"} | json | line_format "{{.error}}"
   ```
   ‚Üí Top errors:
   ```
   Database connection timeout: 45%
   Redis connection refused: 30%
   External API timeout: 25%
   ```

3. **Traces (Failed requests):**
   ```
   {status = error}
   ```
   ‚Üí Th·∫•y t·∫•t c·∫£ traces fail ·ªü Database connection

4. **Metrics (Database):**
   ```promql
   pg_stat_activity_count{state="active"}
   ```
   ‚Üí 100 connections (max = 100)

5. **Root cause:** Connection pool exhausted

6. **Fix:** TƒÉng connection pool size + fix connection leaks

---

## üìä Monitoring Strategy

### Monitoring Levels

```mermaid
graph TB
    L1[Level 1: Infrastructure<br/>Servers, Network, Disk]
    L2[Level 2: Platform<br/>Kubernetes, Docker, Databases]
    L3[Level 3: Application<br/>APIs, Services, Business Logic]
    L4[Level 4: User Experience<br/>Frontend, Mobile, End-to-end]
    
    L1 --> L2
    L2 --> L3
    L3 --> L4
    
    style L1 fill:#ff9999
    style L2 fill:#ffcc99
    style L3 fill:#99ccff
    style L4 fill:#99ff99
```

**Level 1: Infrastructure**
- **Metrics:** CPU, Memory, Disk, Network
- **Tools:** Node Exporter, cAdvisor
- **Alerts:** Disk > 90%, CPU > 90%, Memory > 80%

**Level 2: Platform**
- **Metrics:** Container stats, DB connections, Cache hit ratio
- **Tools:** PostgreSQL Exporter, MongoDB Exporter, Redis Exporter
- **Alerts:** DB connections > 90%, Slow queries, Replication lag

**Level 3: Application**
- **Metrics:** Request rate, Error rate, Latency (RED)
- **Traces:** Request flow, Service dependencies
- **Logs:** Application errors, Business events
- **Alerts:** Error rate > 5%, p95 latency > 500ms

**Level 4: User Experience**
- **Metrics:** Page load time, API response time
- **Traces:** End-to-end request tracing
- **Logs:** User actions, Conversion funnel

---

### Golden Signals (Google SRE)

**4 metrics quan tr·ªçng nh·∫•t:**

1. **Latency:** Th·ªùi gian x·ª≠ l√Ω request
   ```promql
   histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
   ```

2. **Traffic:** Request rate
   ```promql
   rate(http_requests_total[5m])
   ```

3. **Errors:** Error rate
   ```promql
   rate(http_requests_total{status=~"5.."}[5m]) 
   / 
   rate(http_requests_total[5m])
   ```

4. **Saturation:** Resource utilization
   ```promql
   1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)
   ```

---

## üöÄ Getting Started

### 1. Start LGTM Stack

```bash
cd grafana-prometheus
docker-compose up -d

# Verify
docker-compose ps
curl http://localhost:9090  # Prometheus
curl http://localhost:3100  # Loki
curl http://localhost:3200  # Tempo
curl http://localhost:3000  # Grafana
```

### 2. Start Database Test Environment

```bash
cd db
cp .env.example .env
docker-compose up -d

# Verify
docker-compose ps
curl http://localhost:9187/metrics  # PostgreSQL Exporter
curl http://localhost:9216/metrics  # MongoDB Exporter
```

### 3. Start Application

```bash
cd aisoft-backend
npm install
npm start

# Logs s·∫Ω t·ª± ƒë·ªông g·ª≠i ƒë·∫øn Loki
```

### 4. Access Grafana

```
URL: http://localhost:3000
Username: admin
Password: (check docker-compose.yml)
```

**Explore:**
- Metrics: Prometheus datasource
- Logs: Loki datasource
- Traces: Tempo datasource

---

## üìö T√†i li·ªáu Chi ti·∫øt

Sau khi hi·ªÉu overview, ƒë·ªçc c√°c t√†i li·ªáu chi ti·∫øt:

1. **[METRICS.md](./METRICS.md)** - Prometheus, Exporters, PromQL, Alert Rules
2. **[TRACES.md](./TRACES.md)** - OpenTelemetry, Tempo, Distributed Tracing
3. **[LOGS.md](./LOGS.md)** - Loki, Promtail, LogQL, Log Pipelines
4. **[DATABASE-MONITORING.md](./DATABASE-MONITORING.md)** - PostgreSQL & MongoDB Monitoring
5. **[APPLICATION-LOGGING.md](./APPLICATION-LOGGING.md)** - Pino, Loki Integration
6. **[DIAGRAMS.md](./DIAGRAMS.md)** - Mermaid Diagrams

---

## üéì Key Takeaways

‚úÖ **Observability = Metrics + Traces + Logs**  
‚úÖ **Metrics:** Ph√°t hi·ªán v·∫•n ƒë·ªÅ (What?)  
‚úÖ **Traces:** T√¨m bottleneck (Where?)  
‚úÖ **Logs:** Root cause analysis (Why?)  
‚úÖ **LGTM Stack:** Loki + Grafana + Tempo + Prometheus  
‚úÖ **Unified UI:** Grafana cho t·∫•t c·∫£ datasources  
‚úÖ **Correlation:** Jump gi·ªØa metrics ‚Üî traces ‚Üî logs  
‚úÖ **Cost-effective:** Open-source, self-hosted  

---

## üîó Resources

- **Prometheus:** https://prometheus.io/docs/
- **Loki:** https://grafana.com/docs/loki/
- **Tempo:** https://grafana.com/docs/tempo/
- **OpenTelemetry:** https://opentelemetry.io/docs/
- **Grafana:** https://grafana.com/docs/grafana/
- **Pino:** https://getpino.io/

---

**Version:** 1.0.0  
**Last Updated:** 2025-12-30  
**Maintainer:** DevOps Team
