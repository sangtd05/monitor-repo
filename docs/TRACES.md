# TRACES - Há»‡ thá»‘ng Distributed Tracing

## ğŸ¯ Tracing lÃ  gÃ¬ vÃ  Táº¡i sao cáº§n Tracing?

### Äá»‹nh nghÄ©a

**Distributed Tracing** lÃ  ká»¹ thuáº­t theo dÃµi má»™t request khi nÃ³ Ä‘i qua nhiá»u services khÃ¡c nhau trong há»‡ thá»‘ng microservices. Má»—i request Ä‘Æ°á»£c gÃ¡n má»™t **Trace ID** duy nháº¥t, vÃ  má»—i bÆ°á»›c xá»­ lÃ½ trong cÃ¡c services táº¡o ra cÃ¡c **Spans**.

### KhÃ¡i niá»‡m cÆ¡ báº£n

```
Request: GET /api/order/123

Trace ID: abc-def-123
â”‚
â”œâ”€ Span 1: API Gateway (50ms)
â”‚  â”‚
â”‚  â”œâ”€ Span 2: Auth Service (10ms)
â”‚  â”‚
â”‚  â”œâ”€ Span 3: Order Service (35ms)
â”‚     â”‚
â”‚     â”œâ”€ Span 4: Database Query (20ms)
â”‚     â”‚
â”‚     â””â”€ Span 5: Cache Lookup (5ms)
â”‚
â””â”€ Total: 50ms
```

**Trace**: ToÃ n bá»™ journey cá»§a 1 request  
**Span**: 1 Ä‘Æ¡n vá»‹ cÃ´ng viá»‡c trong trace (function call, DB query, HTTP request)  
**Trace ID**: Äá»‹nh danh duy nháº¥t cho trace  
**Span ID**: Äá»‹nh danh duy nháº¥t cho span  
**Parent Span ID**: LiÃªn káº¿t spans thÃ nh cÃ¢y

### Táº¡i sao Tracing quan trá»ng?

#### 1. **Debugging Microservices**

**Váº¥n Ä‘á»**: Request cháº­m, nhÆ°ng khÃ´ng biáº¿t cháº­m á»Ÿ Ä‘Ã¢u?

**KhÃ´ng cÃ³ Tracing:**
```
User: "API /checkout cháº­m quÃ¡!"
Dev: "Hmm... cÃ³ thá»ƒ lÃ :
  - Payment service?
  - Inventory service?
  - Database?
  - Network?
  - ...?"
â†’ Pháº£i check logs tá»«ng service, Ä‘oÃ¡n mÃ²
```

**CÃ³ Tracing:**
```
Trace cho request cháº­m:
â”œâ”€ API Gateway: 2ms âœ…
â”œâ”€ Auth Service: 5ms âœ…
â”œâ”€ Checkout Service: 3ms âœ…
â”œâ”€ Payment Service: 2500ms âŒ â† ÄÃ‚Y Rá»’I!
â”‚  â””â”€ External API call: 2480ms â† Timeout tá»« payment gateway
â””â”€ Inventory Service: 10ms âœ…

â†’ Biáº¿t ngay váº¥n Ä‘á» á»Ÿ Payment Service gá»i external API
```

#### 2. **Performance Optimization**

XÃ¡c Ä‘á»‹nh bottlenecks:
```
Trace: /api/user/profile (total: 450ms)
â”œâ”€ Load user: 50ms
â”œâ”€ Load posts: 200ms â† Cháº­m
â”‚  â”œâ”€ DB query: 180ms â† N+1 query problem
â”‚  â””â”€ Process: 20ms
â”œâ”€ Load friends: 150ms â† Cháº­m
â”‚  â””â”€ DB query: 145ms â† Missing index
â””â”€ Render: 50ms

â†’ Biáº¿t cáº§n optimize 2 queries nÃ y
```

#### 3. **Understanding Dependencies**

Visualize service dependencies:
```
Frontend
   â”‚
   â”œâ”€â”€â–¶ API Gateway
        â”‚
        â”œâ”€â”€â–¶ User Service
        â”‚     â””â”€â”€â–¶ PostgreSQL
        â”‚
        â”œâ”€â”€â–¶ Order Service
        â”‚     â”œâ”€â”€â–¶ MongoDB
        â”‚     â””â”€â”€â–¶ Inventory Service
        â”‚           â””â”€â”€â–¶ Redis
        â”‚
        â””â”€â”€â–¶ Notification Service
              â””â”€â”€â–¶ Email Service (External)
```

#### 4. **Error Correlation**

LiÃªn káº¿t errors qua nhiá»u services:
```
Trace ID: xyz-789
â”œâ”€ Frontend: Error 500
â”œâ”€ API Gateway: Passed through
â”œâ”€ Order Service: Exception thrown
â”‚  â””â”€ Error: "Inventory not available"
â””â”€ Inventory Service: Database connection timeout
   â””â”€ Root cause: PostgreSQL down

â†’ Biáº¿t error 500 á»Ÿ frontend thá»±c ra do PostgreSQL down
```

## ğŸ—ï¸ Kiáº¿n trÃºc Tracing trong Há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DISTRIBUTED TRACING FLOW                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                         â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Backend    â”‚    â”‚   Service A  â”‚    â”‚   Service B  â”‚  â”‚
â”‚  â”‚ (Instrumentedâ”‚    â”‚(Instrumented)â”‚    â”‚(Instrumented)â”‚  â”‚
â”‚  â”‚  with OTEL)  â”‚    â”‚              â”‚    â”‚              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚                   â”‚            â”‚
â”‚         â”‚ OTLP Protocol     â”‚                   â”‚            â”‚
â”‚         â”‚ (gRPC/HTTP)       â”‚                   â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                             â”‚                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  OpenTelemetry      â”‚
                   â”‚  Collector          â”‚
                   â”‚                     â”‚
                   â”‚  Receivers:         â”‚
                   â”‚   â€¢ OTLP gRPC :4317 â”‚
                   â”‚   â€¢ OTLP HTTP :4318 â”‚
                   â”‚                     â”‚
                   â”‚  Processors:        â”‚
                   â”‚   â€¢ Batch           â”‚
                   â”‚   â€¢ Memory Limiter  â”‚
                   â”‚                     â”‚
                   â”‚  Exporters:         â”‚
                   â”‚   â€¢ Tempo           â”‚
                   â”‚   â€¢ Prometheus      â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚                         â”‚
                 â–¼                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Tempo       â”‚      â”‚   Prometheus    â”‚
        â”‚                 â”‚      â”‚                 â”‚
        â”‚ â€¢ Store traces  â”‚      â”‚ â€¢ Store metrics â”‚
        â”‚ â€¢ Query traces  â”‚      â”‚   from spans    â”‚
        â”‚ â€¢ Retention:    â”‚      â”‚   (exemplars)   â”‚
        â”‚   168h (7 days) â”‚      â”‚                 â”‚
        â”‚                 â”‚      â”‚                 â”‚
        â”‚ Storage:        â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ â€¢ Local FS      â”‚
        â”‚ â€¢ /var/tempo    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ Query API
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Grafana      â”‚
        â”‚                 â”‚
        â”‚ â€¢ Trace view    â”‚
        â”‚ â€¢ Service graph â”‚
        â”‚ â€¢ Metrics â†â†’    â”‚
        â”‚   Traces link   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ CÃ¡c ThÃ nh pháº§n Chi tiáº¿t

### 1. OpenTelemetry (OTEL) - Instrumentation Standard

**OpenTelemetry** lÃ  standard má»Ÿ cho observability, cung cáº¥p APIs, SDKs Ä‘á»ƒ instrument applications.

#### Táº¡i sao OpenTelemetry?

**TrÆ°á»›c Ä‘Ã¢y:**
- Jaeger cÃ³ SDK riÃªng
- Zipkin cÃ³ SDK riÃªng
- Vendor X cÃ³ SDK riÃªng
â†’ Äá»•i backend = pháº£i Ä‘á»•i code

**Vá»›i OpenTelemetry:**
- 1 SDK duy nháº¥t
- Há»— trá»£ nhiá»u languages (Go, Java, Python, Node.js, .NET, ...)
- Äá»•i backend chá»‰ cáº§n Ä‘á»•i exporter config
- Vendor-neutral, CNCF project

#### OTLP Protocol

**OTLP** (OpenTelemetry Protocol) lÃ  protocol Ä‘á»ƒ export telemetry data.

**2 variants:**
- **gRPC** (port 4317): Binary, hiá»‡u quáº£, low latency
- **HTTP** (port 4318): Text-based, dá»… debug, firewall-friendly

**Data format:**
```protobuf
Span {
  trace_id: "abc123..."
  span_id: "def456..."
  parent_span_id: "ghi789..."
  name: "GET /api/users"
  kind: SERVER
  start_time: 1735574400000000000
  end_time: 1735574400050000000
  attributes: {
    "http.method": "GET"
    "http.url": "/api/users"
    "http.status_code": 200
  }
  events: [...]
  links: [...]
}
```

### 2. OpenTelemetry Collector - Data Pipeline

**Vai trÃ²**: Nháº­n, xá»­ lÃ½, vÃ  export telemetry data. LÃ  layer trung gian giá»¯a applications vÃ  backends.

#### Táº¡i sao cáº§n Collector?

**KhÃ´ng cÃ³ Collector:**
```
App 1 â”€â”€â–¶ Tempo
App 2 â”€â”€â–¶ Tempo
App 3 â”€â”€â–¶ Tempo
```
- Má»—i app pháº£i biáº¿t Tempo endpoint
- Äá»•i backend = update táº¥t cáº£ apps
- KhÃ´ng cÃ³ buffering â†’ data loss náº¿u Tempo down

**CÃ³ Collector:**
```
App 1 â”€â”€â”
App 2 â”€â”€â”¼â”€â”€â–¶ Collector â”€â”€â–¶ Tempo
App 3 â”€â”€â”˜                â””â”€â”€â–¶ Prometheus
                          â””â”€â”€â–¶ Other backends
```
- Apps chá»‰ cáº§n biáº¿t Collector
- Collector handle buffering, retry
- Centralized processing (sampling, filtering)
- Dá»… dÃ ng thÃªm/Ä‘á»•i backends

#### Cáº¥u hÃ¬nh trong Há»‡ thá»‘ng

```yaml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
```

**Giáº£i thÃ­ch:**
- Listen trÃªn cáº£ gRPC vÃ  HTTP
- `0.0.0.0`: Accept connections tá»« má»i network interface
- Applications gá»­i traces Ä‘áº¿n `otel-collector:4317` (gRPC) hoáº·c `:4318` (HTTP)

#### Processors

```yaml
processors:
  batch:
    timeout: 5s
    send_batch_size: 8192
  memory_limiter:
    check_interval: 1s
    limit_mib: 400
    spike_limit_mib: 100
```

**1. Batch Processor**

**Má»¥c Ä‘Ã­ch**: Gá»™p nhiá»u spans thÃ nh batches trÆ°á»›c khi export.

**Táº¡i sao batch?**
- **Performance**: 1 request vá»›i 1000 spans tá»‘t hÆ¡n 1000 requests
- **Network efficiency**: Giáº£m overhead
- **Backend friendly**: Tempo xá»­ lÃ½ batches hiá»‡u quáº£ hÆ¡n

**Cáº¥u hÃ¬nh:**
- `timeout: 5s`: Gá»­i batch sau 5s ká»ƒ tá»« span Ä‘áº§u tiÃªn
- `send_batch_size: 8192`: Gá»­i khi Ä‘á»§ 8192 spans (hoáº·c timeout)

**Trade-off:**
- Batch lá»›n + timeout dÃ i = hiá»‡u quáº£ nhÆ°ng delay cao
- Batch nhá» + timeout ngáº¯n = real-time nhÆ°ng overhead cao

**2. Memory Limiter Processor**

**Má»¥c Ä‘Ã­ch**: TrÃ¡nh OOM (Out of Memory) khi traffic spike.

**CÃ¡ch hoáº¡t Ä‘á»™ng:**
```
Normal: Memory < 400MB
  â†’ Accept all data

Soft limit: Memory > 400MB
  â†’ Start dropping data (probabilistic)

Hard limit: Memory > 500MB (400 + 100 spike)
  â†’ Drop all new data
  â†’ Force GC
```

**Táº¡i sao cáº§n?**
- Traffic spike â†’ collector nháº­n quÃ¡ nhiá»u data
- Backend cháº­m â†’ data queue up trong memory
- KhÃ´ng cÃ³ limiter â†’ OOM â†’ collector crash â†’ máº¥t háº¿t data
- CÃ³ limiter â†’ drop má»™t pháº§n data â†’ collector sá»‘ng â†’ giá»¯ Ä‘Æ°á»£c pháº§n cÃ²n láº¡i

#### Exporters

```yaml
exporters:
  otlp/tempo:
    endpoint: tempo:4317
    tls:
      insecure: true
  prometheus:
    endpoint: 0.0.0.0:8889
    namespace: otel
```

**1. OTLP Exporter (to Tempo)**

- Gá»­i traces Ä‘áº¿n Tempo qua gRPC
- `insecure: true`: KhÃ´ng dÃ¹ng TLS (internal network)
- Production nÃªn enable TLS

**2. Prometheus Exporter**

**Chá»©c nÄƒng Ä‘áº·c biá»‡t**: Generate metrics tá»« traces!

**Metrics tá»« Spans:**
```
Span: GET /api/users (duration: 50ms, status: 200)

â†’ Generates metrics:
otel_http_request_duration_milliseconds{method="GET", endpoint="/api/users", status="200"} 50
otel_http_requests_total{method="GET", endpoint="/api/users", status="200"} 1
```

**Lá»£i Ã­ch:**
- KhÃ´ng cáº§n instrument metrics riÃªng
- Metrics vÃ  traces consistent (cÃ¹ng source)
- Exemplars: Link tá»« metric spike Ä‘áº¿n trace cá»¥ thá»ƒ

#### Service Pipeline

```yaml
service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlp/tempo]
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [prometheus]
```

**Giáº£i thÃ­ch:**
- **Traces pipeline**: OTLP â†’ Memory Limiter â†’ Batch â†’ Tempo
- **Metrics pipeline**: OTLP â†’ Memory Limiter â†’ Batch â†’ Prometheus

**Táº¡i sao processors theo thá»© tá»± nÃ y?**
1. **Memory Limiter trÆ°á»›c**: Drop data sá»›m náº¿u quÃ¡ táº£i
2. **Batch sau**: Chá»‰ batch data há»£p lá»‡

### 3. Tempo - Trace Storage Backend

**Tempo** lÃ  distributed tracing backend cá»§a Grafana Labs, tá»‘i Æ°u cho cost-effective storage.

#### Äáº·c Ä‘iá»ƒm

**1. Write Path:**
```
Collector â”€â”€â–¶ Distributor â”€â”€â–¶ Ingester â”€â”€â–¶ Storage
                                â”‚
                                â””â”€â”€â–¶ WAL (Write-Ahead Log)
```

- **Distributor**: Nháº­n traces, hash trace_id Ä‘á»ƒ route Ä‘áº¿n ingester
- **Ingester**: Buffer traces trong memory, flush Ä‘á»‹nh ká»³
- **WAL**: Durability, trÃ¡nh máº¥t data náº¿u crash

**2. Storage:**

```yaml
storage:
  trace:
    backend: local
    local:
      path: /var/tempo/traces
    wal:
      path: /var/tempo/wal
```

**Backend options:**
- **local**: Filesystem (development/small scale)
- **s3**: AWS S3 (production)
- **gcs**: Google Cloud Storage
- **azure**: Azure Blob Storage

**Táº¡i sao dÃ¹ng object storage (S3/GCS)?**
- **Cost**: $0.023/GB/month (S3) vs $0.10/GB/month (EBS)
- **Scalability**: Unlimited storage
- **Durability**: 99.999999999% (11 nines)

**3. Compaction:**

```yaml
compactor:
  compaction:
    block_retention: 168h  # 7 days
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**
```
Ingester táº¡o blocks má»—i 5 phÃºt:
block-001 (0-5min)
block-002 (5-10min)
block-003 (10-15min)
...

Compactor gá»™p blocks:
block-001 + block-002 + ... + block-12 â†’ block-hour-1 (0-60min)
block-hour-1 + ... + block-hour-24 â†’ block-day-1 (0-24h)

XÃ³a blocks cÅ© hÆ¡n 168h
```

**Lá»£i Ã­ch:**
- Giáº£m sá»‘ lÆ°á»£ng files
- Query nhanh hÆ¡n (Ã­t files pháº£i scan)
- Tiáº¿t kiá»‡m storage (compression tá»‘t hÆ¡n)

#### Metrics Generator

**TÃ­nh nÄƒng Ä‘áº·c biá»‡t**: Tempo cÃ³ thá»ƒ generate metrics tá»« traces!

```yaml
metrics_generator:
  registry:
    external_labels:
      source: tempo
      cluster: docker-compose
    collection_interval: 15s
  storage:
    path: /var/tempo/generator/wal
    remote_write:
      - url: http://prometheus:9090/api/v1/write
        send_exemplars: true
```

**Processor types:**

**1. Service Graphs**

```yaml
processor:
  service_graphs:
    max_items: 10000
```

**Output**: Metrics vá» service-to-service calls

```promql
# Request rate giá»¯a services
traces_service_graph_request_total{client="frontend", server="api-gateway"} 1000

# Latency
traces_service_graph_request_duration_seconds{client="frontend", server="api-gateway"} 0.05

# Failed requests
traces_service_graph_request_failed_total{client="frontend", server="api-gateway"} 10
```

**Sá»­ dá»¥ng**: Váº½ service dependency graph trong Grafana

**2. Span Metrics**

```yaml
processor:
  span_metrics:
    dimensions:
      - http.method
      - http.target
      - http.status_code
      - service.version
```

**Output**: Metrics tá»« span attributes

```promql
# Request duration by endpoint
traces_span_metrics_duration_seconds{http_method="GET", http_target="/api/users", http_status_code="200"}

# Request count
traces_span_metrics_calls_total{http_method="POST", http_target="/api/orders"}
```

**3. Exemplars**

**Exemplars** = Link tá»« metric data point Ä‘áº¿n trace cá»¥ thá»ƒ.

```
Metric: http_request_duration_seconds
Value: 0.5s at timestamp 1735574400

Exemplar: {
  value: 0.5
  timestamp: 1735574400
  trace_id: "abc123..."  â† Link to trace
  span_id: "def456..."
}
```

**Workflow trong Grafana:**
```
1. Xem metric graph: Response time tÄƒng Ä‘á»™t ngá»™t
2. Click vÃ o spike point
3. Grafana hiá»ƒn thá»‹ exemplar traces
4. Click vÃ o trace â†’ Xem chi tiáº¿t trace
5. Debug táº¡i sao request nÃ y cháº­m
```

**Lá»£i Ã­ch:**
- Jump tá»« "cÃ³ váº¥n Ä‘á»" (metrics) â†’ "váº¥n Ä‘á» cá»¥ thá»ƒ lÃ  gÃ¬" (trace)
- KhÃ´ng cáº§n search trace ID manually

### 4. Trace Query vÃ  Visualization

#### Query Traces trong Grafana

**1. Trace ID Search:**
```
Trace ID: abc-def-123
â†’ Hiá»ƒn thá»‹ toÃ n bá»™ trace vá»›i táº¥t cáº£ spans
```

**2. TraceQL (Trace Query Language):**

```traceql
# TÃ¬m traces cháº­m
{ duration > 1s }

# Traces cÃ³ errors
{ status = error }

# Traces tá»« service cá»¥ thá»ƒ
{ service.name = "api-gateway" }

# Traces vá»›i HTTP 500
{ span.http.status_code = 500 }

# Complex query
{
  service.name = "order-service" &&
  duration > 500ms &&
  span.http.method = "POST"
}
```

**3. Metrics to Traces:**

```
Prometheus query: rate(http_requests_total[5m])
â†’ Click vÃ o data point
â†’ Grafana tÃ¬m exemplar trace
â†’ Jump to trace view
```

#### Trace Visualization

**Waterfall View:**
```
Trace: GET /api/order/123 (total: 450ms)
â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Timeline
â”‚
â”œâ”€ API Gateway                    [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 50ms
â”‚  â”‚
â”‚  â”œâ”€ Auth Service                [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 10ms
â”‚  â”‚
â”‚  â””â”€ Order Service               [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 350ms
â”‚     â”‚
â”‚     â”œâ”€ Validate Order           [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 20ms
â”‚     â”‚
â”‚     â”œâ”€ Check Inventory          [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 50ms
â”‚     â”‚  â”‚
â”‚     â”‚  â””â”€ Redis GET             [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 5ms
â”‚     â”‚
â”‚     â”œâ”€ Process Payment          [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 250ms â† Bottleneck!
â”‚     â”‚  â”‚
â”‚     â”‚  â””â”€ External Payment API  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 240ms
â”‚     â”‚
â”‚     â””â”€ Save to DB               [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 30ms
â”‚        â”‚
â”‚        â””â”€ PostgreSQL INSERT     [â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 25ms
â”‚
â””â”€ Response                       [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0ms
```

**Span Details:**
```
Span: Process Payment
â”œâ”€ Duration: 250ms
â”œâ”€ Status: OK
â”œâ”€ Attributes:
â”‚  â”œâ”€ payment.method: "credit_card"
â”‚  â”œâ”€ payment.amount: 99.99
â”‚  â”œâ”€ payment.currency: "USD"
â”‚  â””â”€ payment.gateway: "stripe"
â”œâ”€ Events:
â”‚  â”œâ”€ [10ms] Payment request sent
â”‚  â”œâ”€ [240ms] Payment response received
â”‚  â””â”€ [250ms] Payment confirmed
â””â”€ Links:
   â””â”€ Related trace: order-confirmation-email
```

**Service Graph:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ 1000 req/s
     â”‚ 50ms avg
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Gateway  â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
   â”‚        â”‚
   â”‚        â”‚ 800 req/s
   â”‚        â”‚ 100ms avg
   â”‚        â–¼
   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   â”‚   Auth     â”‚
   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ 1000 req/s
   â”‚ 200ms avg
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Order Service â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
   â”‚        â”‚
   â”‚        â”‚ 500 req/s
   â”‚        â”‚ 50ms avg
   â”‚        â–¼
   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   â”‚ Inventory  â”‚
   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ 1000 req/s
   â”‚ 150ms avg
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Payment    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Instrumentation Best Practices

### 1. Span Naming

**Good:**
```
GET /api/users
POST /api/orders
SELECT users WHERE id = ?
Redis GET user:123
```

**Bad:**
```
handleRequest
doWork
query
fetch
```

**Principles:**
- Descriptive: Biáº¿t span lÃ m gÃ¬
- Consistent: CÃ¹ng format trong toÃ n bá»™ há»‡ thá»‘ng
- Low cardinality: KhÃ´ng include IDs, user-specific data

### 2. Span Attributes

**Good:**
```javascript
span.setAttribute("http.method", "GET")
span.setAttribute("http.url", "/api/users")
span.setAttribute("http.status_code", 200)
span.setAttribute("db.system", "postgresql")
span.setAttribute("db.statement", "SELECT * FROM users WHERE id = ?")
```

**Bad:**
```javascript
span.setAttribute("user_id", "12345")  // High cardinality
span.setAttribute("request_body", "{...}")  // Too large
span.setAttribute("password", "secret")  // Sensitive data
```

**Semantic Conventions**: Sá»­ dá»¥ng standard attributes tá»« OpenTelemetry
- `http.*`: HTTP requests
- `db.*`: Database operations
- `messaging.*`: Message queues
- `rpc.*`: RPC calls

### 3. Span Events

**Sá»­ dá»¥ng events cho Ä‘iá»ƒm quan trá»ng trong span:**

```javascript
span.addEvent("cache_miss", {
  "cache.key": "user:123",
  "cache.ttl": 3600
})

span.addEvent("validation_failed", {
  "validation.field": "email",
  "validation.error": "invalid format"
})

span.addEvent("retry_attempt", {
  "retry.count": 2,
  "retry.max": 3
})
```

### 4. Error Handling

```javascript
try {
  // Do work
  span.setStatus({ code: SpanStatusCode.OK })
} catch (error) {
  span.setStatus({
    code: SpanStatusCode.ERROR,
    message: error.message
  })
  span.recordException(error)
  throw error
}
```

### 5. Sampling

**Váº¥n Ä‘á»**: 100% traces = quÃ¡ nhiá»u data, tá»‘n storage, tá»‘n tiá»n.

**Giáº£i phÃ¡p**: Sampling - chá»‰ giá»¯ má»™t pháº§n traces.

**Sampling strategies:**

**1. Head-based Sampling** (quyáº¿t Ä‘á»‹nh á»Ÿ Ä‘áº§u trace):
```
Random: 10% of all traces
Rate limiting: Max 100 traces/second
```

**2. Tail-based Sampling** (quyáº¿t Ä‘á»‹nh sau khi trace hoÃ n thÃ nh):
```
Keep if:
  - Duration > 1s
  - Has errors
  - Status code 5xx
  - Random 1% of normal requests
```

**Cáº¥u hÃ¬nh trong Collector:**
```yaml
processors:
  probabilistic_sampler:
    sampling_percentage: 10  # Keep 10%
  
  tail_sampling:
    policies:
      - name: errors
        type: status_code
        status_code: {status_codes: [ERROR]}
      - name: slow
        type: latency
        latency: {threshold_ms: 1000}
      - name: random
        type: probabilistic
        probabilistic: {sampling_percentage: 1}
```

## ğŸ’¡ Use Cases

### 1. Debugging Slow Requests

**Scenario**: API `/api/dashboard` Ä‘Ã´i khi cháº­m.

**BÆ°á»›c 1**: Query slow traces
```traceql
{
  span.http.target = "/api/dashboard" &&
  duration > 2s
}
```

**BÆ°á»›c 2**: PhÃ¢n tÃ­ch waterfall
```
Trace 1: 3.5s total
â”œâ”€ Load user: 50ms
â”œâ”€ Load widgets: 3.2s â† Bottleneck
â”‚  â””â”€ DB query: 3.1s â† N+1 query
â””â”€ Render: 200ms
```

**BÆ°á»›c 3**: Fix N+1 query, verify
```
Trace 2 (after fix): 400ms total
â”œâ”€ Load user: 50ms
â”œâ”€ Load widgets: 150ms â† Fixed!
â”‚  â””â”€ DB query: 100ms
â””â”€ Render: 200ms
```

### 2. Finding Error Root Cause

**Scenario**: User bÃ¡o lá»—i 500.

**BÆ°á»›c 1**: TÃ¬m trace vá»›i error
```traceql
{
  span.http.status_code = 500 &&
  service.name = "api-gateway"
}
```

**BÆ°á»›c 2**: Follow trace tree
```
API Gateway: 500 â† User tháº¥y
â””â”€ Order Service: Exception
   â””â”€ Payment Service: Timeout
      â””â”€ External API: Connection refused
         â†’ Root cause: Payment gateway down
```

### 3. Capacity Planning

**Query service graph metrics:**
```promql
# Request rate trend
rate(traces_service_graph_request_total[1h])

# P95 latency trend
histogram_quantile(0.95, 
  rate(traces_service_graph_request_duration_seconds_bucket[5m])
)
```

**Insight:**
- Order Service: 1000 req/s hiá»‡n táº¡i
- TÄƒng 20%/thÃ¡ng
- P95 latency: 200ms (gáº§n limit 250ms)
â†’ Cáº§n scale trong 2 thÃ¡ng

## ğŸ“ Tá»•ng káº¿t

### Tracing Flow Summary

1. **Application** instrument vá»›i OpenTelemetry SDK
2. **Spans** Ä‘Æ°á»£c táº¡o cho má»—i operation
3. **OTLP** gá»­i spans Ä‘áº¿n OpenTelemetry Collector
4. **Collector** process (batch, sample) vÃ  export
5. **Tempo** lÆ°u trá»¯ traces
6. **Metrics Generator** táº¡o metrics tá»« spans â†’ Prometheus
7. **Grafana** query vÃ  visualize traces

### Key Takeaways

âœ… **Tracing = Following requests through microservices**  
âœ… **Trace = Collection of spans vá»›i cÃ¹ng trace_id**  
âœ… **OpenTelemetry = Vendor-neutral instrumentation standard**  
âœ… **Collector = Central pipeline cho telemetry data**  
âœ… **Tempo = Cost-effective trace storage**  
âœ… **Exemplars = Bridge tá»« metrics â†’ traces**  

### Khi nÃ o dÃ¹ng Tracing?

- âœ… Debug microservices (request Ä‘i qua nhiá»u services)
- âœ… TÃ¬m performance bottlenecks
- âœ… Understand service dependencies
- âœ… Root cause analysis cho errors
- âœ… Latency breakdown (thá»i gian á»Ÿ Ä‘Ã¢u?)
- âŒ System-wide trends (dÃ¹ng Metrics)
- âŒ Detailed logs (dÃ¹ng Logs)
- âŒ Audit trail (dÃ¹ng Logs)
