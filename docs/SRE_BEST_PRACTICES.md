# SRE Best Practices & Monitoring Standards for LGTM Stack

## üìä T·ªïng quan

T√†i li·ªáu n√†y ƒë·ªãnh nghƒ©a c√°c ti√™u chu·∫©n gi√°m s√°t (Monitoring Standards) v√† ph∆∞∆°ng ph√°p ƒë√°nh gi√° ƒë·ªô tin c·∫≠y (Reliability Evaluation) cho h·ªá th·ªëng s·ª≠ d·ª•ng **LGTM Stack (Loki, Grafana, Tempo, Mimir)** v√† **Grafana Alloy**.

N√≥ k·∫øt h·ª£p c√°c l√Ω thuy·∫øt SRE chu·∫©n m·ª±c c·ªßa Google v·ªõi c√°c h∆∞·ªõng d·∫´n th·ª±c h√†nh chi ti·∫øt, gi·∫£i th√≠ch **T·∫†I SAO** c·∫ßn l√†m v·∫≠y v√† l√†m **NH∆Ø TH·∫æ N√ÄO**.

---

## üéØ 1. The Four Golden Signals (Google SRE)

Ch√∫ng t√¥i s·ª≠ d·ª•ng 4 t√≠n hi·ªáu v√†ng l√†m kim ch·ªâ nam cho vi·ªác gi√°m s√°t m·ªçi service trong h·ªá th·ªëng. Google SRE team ph√°t hi·ªán r·∫±ng **80% v·∫•n ƒë·ªÅ** c√≥ th·ªÉ ph√°t hi·ªán qua 4 metrics n√†y.

### 1.1. Latency - ƒê·ªô tr·ªÖ
*   **ƒê·ªãnh nghƒ©a:** Th·ªùi gian ƒë·ªÉ x·ª≠ l√Ω m·ªôt request (t√≠nh t·ª´ khi nh·∫≠n ƒë·∫øn khi ph·∫£n h·ªìi).
*   **Metrics (PromQL):**
    ```promql
    # P95 Latency - 95% requests nhanh h∆°n ng∆∞·ª°ng n√†y
    histogram_quantile(0.95, sum(rate(traces_spanmetrics_latency_bucket[5m])) by (le, service_name))
    ```

#### üí° Deep Dive: T·∫°i sao kh√¥ng d√πng Average?
**Scenario th·ª±c t·∫ø:**
*   Average latency: 100ms ‚úÖ (Tr√¥ng c√≥ v·∫ª ·ªïn).
*   Nh∆∞ng users v·∫´n k√™u ch·∫≠m!
*   **L√Ω do**: Average b·ªã "k√©o" xu·ªëng b·ªüi h√†ng ng√†n requests si√™u nhanh (cache hit). Trong khi ƒë√≥, 5% users b·ªã timeout (30s).
*   **Gi·∫£i ph√°p**: Monitor **Percentiles**.
    *   **P50 (Median)**: Tr·∫£i nghi·ªám c·ªßa ƒëa s·ªë users.
    *   **P95**: Tr·∫£i nghi·ªám c·ªßa users khi h·ªá th·ªëng t·∫£i cao.
    *   **P99**: C√°c case ch·∫≠m nh·∫•t (th∆∞·ªùng l√† l·ªói).

### 1.2. Traffic - L∆∞u l∆∞·ª£ng
*   **ƒê·ªãnh nghƒ©a:** Nhu c·∫ßu s·ª≠ d·ª•ng h·ªá th·ªëng (Requests/sec, Transactions/sec).
*   **Metrics (PromQL):**
    ```promql
    # Request per second (RPS)
    sum(rate(traces_spanmetrics_calls_total[1m])) by (service_name)
    ```

#### üí° Deep Dive: Pattern Recognition
Traffic th∆∞·ªùng tu√¢n theo quy lu·∫≠t (Ng√†y/ƒê√™m, Cu·ªëi tu·∫ßn).
*   **T·∫°i sao c·∫ßn monitor?**: ƒê·ªÉ ph√°t hi·ªán b·∫•t th∆∞·ªùng (Anomaly).
*   **V√≠ d·ª•**: Traffic l√∫c 3h s√°ng ƒë·ªôt ng·ªôt tƒÉng g·∫•p 10 l·∫ßn -> C√≥ th·ªÉ l√† **DDoS** ho·∫∑c **Crawl Bot**.
*   **Action**: Alert n·∫øu traffic tƒÉng ƒë·ªôt bi·∫øn > 50% so v·ªõi c√πng k·ª≥ tu·∫ßn tr∆∞·ªõc (`offset 1w`).

### 1.3. Errors - L·ªói
*   **ƒê·ªãnh nghƒ©a:** T·ª∑ l·ªá requests th·∫•t b·∫°i (5xx codes, exceptions).
*   **Metrics (PromQL & LogQL):**
    ```promql
    # Error Rate %
    sum(rate(traces_spanmetrics_calls_total{status_code="STATUS_CODE_ERROR"}[5m])) / sum(rate(traces_spanmetrics_calls_total[5m]))
    ```

#### üí° Deep Dive: 4xx vs 5xx
*   **4xx (Client Error)**: User nh·∫≠p sai, Unauthorized. Th∆∞·ªùng kh√¥ng ph·∫£i l·ªói h·ªá th·ªëng (tr·ª´ khi spike ƒë·ªôt bi·∫øn do t·∫•n c√¥ng).
*   **5xx (Server Error)**: Bug code, DB ch·∫øt, Timeout. **ƒê√ÇY** l√† l·ªói c·∫ßn ƒë√°nh th·ª©c Dev d·∫≠y l√∫c 2h s√°ng.
*   **Rule**: Ch·ªâ Alert P1/P2 cho l·ªói 5xx.

### 1.4. Saturation - ƒê·ªô b√£o h√≤a
*   **ƒê·ªãnh nghƒ©a:** M·ª©c ƒë·ªô "ƒë·∫ßy" c·ªßa t√†i nguy√™n (Full CPU, Full Disk, Full Connection Pool).
*   **Metrics (PromQL):**
    ```promql
    # Prediction: Disk s·∫Ω ƒë·∫ßy trong 24h t·ªõi?
    predict_linear(node_filesystem_free_bytes[1h], 24*3600) < 0
    ```

#### üí° Deep Dive: Predict tr∆∞·ªõc khi qu√° mu·ªôn
ƒê·ª´ng ƒë·ª£i disk 100% m·ªõi b√°o. H√£y b√°o khi **"v·ªõi t·ªëc ƒë·ªô n√†y, 4 ti·∫øng n·ªØa s·∫Ω ƒë·∫ßy"**.
*   **Benefit**: C√≥ th·ªùi gian ƒë·ªÉ clean logs ho·∫∑c resize volume m√† kh√¥ng g√¢y downtime.

---

## üìà 2. SLI, SLO & Error Budgets

ƒê√¢y l√† c√¥ng c·ª• ƒë·ªÉ c√¢n b·∫±ng gi·ªØa **Innovation** (Feature m·ªõi) v√† **Stability** (·ªîn ƒë·ªãnh).

### Service Level Objective (SLO)
L√† cam k·∫øt ƒë·ªô tin c·∫≠y. V√≠ d·ª•: "99.9% requests th√†nh c√¥ng".

### Error Budget (Ng√¢n s√°ch l·ªói)
N·∫øu SLO l√† 99.9% => Ch√∫ng ta ƒë∆∞·ª£c ph√©p l·ªói **0.1%**.
*   Trong 1 th√°ng (43,200 ph√∫t), 0.1% t∆∞∆°ng ƒë∆∞∆°ng **43 ph√∫t**.
*   ƒê√¢y l√† "ng√¢n s√°ch" ƒë·ªÉ ti√™u x√†i cho vi·ªác deploy, th·ª≠ nghi·ªám.

#### üí° Quy t·∫Øc Error Budget
1.  **C√≤n nhi·ªÅu Budget (>50%)**: Team ƒë∆∞·ª£c ph√©p deploy tho·∫£i m√°i, th·ª≠ nghi·ªám c√¥ng ngh·ªá m·ªõi.
2.  **H·∫øt Budget (0%)**: **FREEZE**. Ng∆∞ng to√†n b·ªô feature deploy. To√†n team t·∫≠p trung s·ª≠a l·ªói v√† c·∫£i thi·ªán ƒë·ªô ·ªïn ƒë·ªãnh cho ƒë·∫øn khi sang th√°ng m·ªõi (reset budget).

---

## üé® 3. Dashboard Design Standards

### Hierarchy Approach (Ph√¢n c·∫•p)

**Level 1: Overview (Glance trong 5 gi√¢y)**
*   **M·ª•c ƒë√≠ch**: S·∫øp ho·∫∑c Operator nh√¨n v√†o bi·∫øt ngay h·ªá th·ªëng S·ªëng hay Ch·∫øt.
*   **N·ªôi dung**: 4 Golden Signals c·ªßa to√†n h·ªá th·ªëng (Traffic t·ªïng, Error rate t·ªïng). M√†u Xanh/ƒê·ªè r√µ r√†ng.

**Level 2: Service Dashboard (Drill down)**
*   **M·ª•c ƒë√≠ch**: Dev t√¨m l·ªói c·ªßa Service m√¨nh.
*   **N·ªôi dung**: Chi ti·∫øt t·ª´ng API, latency t·ª´ng endpoint, dependencies (Redis/DB) c·ªßa service ƒë√≥.

**Level 3: Deep Dive (Debug)**
*   **M·ª•c ƒë√≠ch**: Database Administrator (DBA) debug.
*   **N·ªôi dung**: Slow query logs, Buffer pool hit ratio, Lock wait time.

### Anti-Patterns (C·∫ßn tr√°nh)
*   ‚ùå **Too Many Panels**: Dashboard c√≥ 50 bi·ªÉu ƒë·ªì => Kh√¥ng ai xem. T·ªëi ƒëa 10-12 panels "ƒë·∫Øt gi√°" nh·∫•t.
*   ‚ùå **No Context**: Bi·ªÉu ƒë·ªì CPU cao 80% nh∆∞ng kh√¥ng bi·∫øt b√¨nh th∆∞·ªùng l√† bao nhi√™u. C·∫ßn v·∫Ω th√™m ƒë∆∞·ªùng Threshold (ng∆∞·ª°ng) tr√™n bi·ªÉu ƒë·ªì.

---

## üõ°Ô∏è 4. Observability Maturity Model

H·ªá th·ªëng hi·ªán t·∫°i ƒëang ·ªü **Level 3 (Predictive)** nh·ªù LGTM Stack.

| Level | ƒê·∫∑c ƒëi·ªÉm | V√≠ d·ª• th·ª±c t·∫ø |
|-------|----------|---------------|
| **1. Reactive** | Ch·ªØa ch√°y | User b√°o "Web s·∫≠p r·ªìi" m·ªõi bi·∫øt. Team nh√°o nh√†o log v√†o server check. |
| **2. Proactive** | Ph√≤ng ng·ª´a | C√≥ Alert "Disk > 90%". Team v√†o d·ªçn d·∫πp tr∆∞·ªõc khi s·∫≠p. |
| **3. Predictive** | D·ª± b√°o | Alert "Disk s·∫Ω ƒë·∫ßy trong 3 ng√†y n·ªØa". Team c√≥ k·∫ø ho·∫°ch n√¢ng c·∫•p thong th·∫£. (LGTM Stack ƒëang ·ªü ƒë√¢y) |
| **4. Autonomous** | T·ª± h√†nh | H·ªá th·ªëng th·∫•y traffic tƒÉng -> T·ª± g·ªçi API cloud t·∫°o th√™m server. Th·∫•y Disk ƒë·∫ßy -> T·ª± ch·∫°y script x√≥a log c≈©. |

---

## ‚úÖ 5. Practical Implementation Guide (L·ªô tr√¨nh cho SRE)

D∆∞·ªõi ƒë√¢y l√† checklist ƒë·ªÉ n√¢ng c·∫•p h·ªá th·ªëng monitoring c·ªßa b·∫°n theo t·ª´ng tu·∫ßn:

**Tu·∫ßn 1: Implement Golden Signals**
- [ ] G·∫Øn th∆∞ vi·ªán metrics (Prometheus/OTEL) v√†o t·∫•t c·∫£ Services.
- [ ] V·∫Ω Dashboard Level 1 hi·ªÉn th·ªã 4 signals n√†y.

**Tu·∫ßn 2: Define SLO**
- [ ] H·ªçp v·ªõi Product Owner ch·ªët con s·ªë: 99% hay 99.9%?
- [ ] C·∫•u h√¨nh Prometheus Rule ƒë·ªÉ t√≠nh to√°n SLI/SLO h√†ng ng√†y.

**Tu·∫ßn 3: Improve Alerts (Quality over Quantity)**
- [ ] Review l·∫°i to√†n b·ªô alerts. T·∫Øt c√°c alert "nh·∫£m" (spam message m√† kh√¥ng c·∫ßn action).
- [ ] Th√™m Runbook link v√†o description c·ªßa m·ªói alert quan tr·ªçng.

**Tu·∫ßn 4: Automation**
- [ ] Vi·∫øt script t·ª± ƒë·ªông d·ªçn disk/log khi c√≥ c·∫£nh b√°o.
- [ ] C·∫•u h√¨nh Auto-scaling cho Kubernetes/Docker Swarm (n·∫øu c√≥).

---

## üìö 6. Resources

*   **Books**: "Site Reliability Engineering" (Google), "Observability Engineering".
*   **Docs**:
    *   [Prometheus Best Practices](https://prometheus.io/docs/practices/)
    *   [Grafana Loki Best Practices](https://grafana.com/docs/loki/latest/best-practices/)
