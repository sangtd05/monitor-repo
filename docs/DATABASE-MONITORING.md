# DATABASE MONITORING - Gi√°m s√°t Database Test Environment

## üéØ M·ª•c ƒë√≠ch c·ªßa Database Test Environment

### T·∫°i sao c·∫ßn m√¥i tr∆∞·ªùng test ri√™ng cho database monitoring?

Trong production, vi·ªác enable logging chi ti·∫øt v√† profiling c√≥ th·ªÉ ·∫£nh h∆∞·ªüng performance. M√¥i tr∆∞·ªùng test n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ:

1. **Th·ª≠ nghi·ªám c·∫•u h√¨nh logging** tr∆∞·ªõc khi √°p d·ª•ng l√™n production
2. **Validate log parsing** trong Promtail pipeline
3. **Test alert rules** cho database metrics
4. **H·ªçc c√°ch analyze** database logs v√† metrics
5. **Benchmark performance impact** c·ªßa logging/profiling

### ƒêi·ªÉm kh√°c bi·ªát v·ªõi Production

| Aspect | Test Environment | Production |
|--------|------------------|------------|
| **Logging Level** | ALL statements | Ch·ªâ slow queries (>100ms) |
| **Profiling** | 100% operations | Sampling (1-10%) |
| **Log Retention** | 7 days | 30+ days |
| **Ports** | Internal only | C√≥ th·ªÉ expose |
| **Resources** | Minimal | Optimized |

## üèóÔ∏è Ki·∫øn tr√∫c Database Monitoring

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Database Test Environment (10.99.3.67)         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL 16     ‚îÇ         ‚îÇ   MongoDB 7        ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  :5432 (internal)  ‚îÇ         ‚îÇ  :27017 (internal) ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ         ‚îÇ                    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ Logging:           ‚îÇ         ‚îÇ Logging:           ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ ALL statements   ‚îÇ         ‚îÇ ‚Ä¢ Verbose mode     ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Connections      ‚îÇ         ‚îÇ ‚Ä¢ All operations   ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Slow queries     ‚îÇ         ‚îÇ ‚Ä¢ Profiling 100%   ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Checkpoints      ‚îÇ         ‚îÇ ‚Ä¢ Auth events      ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Lock waits       ‚îÇ         ‚îÇ ‚Ä¢ Slow queries     ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ         ‚îÇ                    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ Logs ‚Üí Volume:     ‚îÇ         ‚îÇ Logs ‚Üí Volume:     ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ postgres-data      ‚îÇ         ‚îÇ mongodb-logs       ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ /pg_log/*.log      ‚îÇ         ‚îÇ /mongod.log        ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ           ‚îÇ                              ‚îÇ                   ‚îÇ
‚îÇ           ‚îÇ SQL queries                  ‚îÇ MongoDB commands  ‚îÇ
‚îÇ           ‚îÇ (via network)                ‚îÇ (via network)     ‚îÇ
‚îÇ           ‚ñº                              ‚ñº                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ Postgres Exporter  ‚îÇ         ‚îÇ MongoDB Exporter   ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ :9187              ‚îÇ         ‚îÇ :9216              ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ         ‚îÇ                    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ Metrics:           ‚îÇ         ‚îÇ Metrics:           ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Connections      ‚îÇ         ‚îÇ ‚Ä¢ Connections      ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Query stats      ‚îÇ         ‚îÇ ‚Ä¢ Operations       ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Table sizes      ‚îÇ         ‚îÇ ‚Ä¢ Latency          ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Replication lag  ‚îÇ         ‚îÇ ‚Ä¢ Cache hit ratio  ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Deadlocks        ‚îÇ         ‚îÇ ‚Ä¢ Replication lag  ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ           ‚îÇ                              ‚îÇ                   ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                          ‚îÇ                                   ‚îÇ
‚îÇ                          ‚îÇ HTTP /metrics                     ‚îÇ
‚îÇ                          ‚îÇ (Pull by Prometheus)              ‚îÇ
‚îÇ                          ‚ñº                                   ‚îÇ
‚îÇ                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ                 ‚îÇ   Prometheus    ‚îÇ (External Server)        ‚îÇ
‚îÇ                 ‚îÇ   :9090         ‚îÇ                          ‚îÇ
‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ              Promtail (Log Collector)             ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ                                                    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  Volumes mounted:                                 ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ postgres-data:/var/log/postgres (read-only)   ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ mongodb-logs:/var/log/mongodb (read-only)     ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ                                                    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  Jobs:                                            ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  1. PostgreSQL logs                               ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ     - Parse multiline SQL                         ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ     - Extract: user, db, app, client, level       ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ                                                    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  2. MongoDB logs                                  ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ     - Parse JSON format                           ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ     - Extract: severity, component, message       ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                         ‚îÇ                                    ‚îÇ
‚îÇ                         ‚îÇ HTTP Push                          ‚îÇ
‚îÇ                         ‚îÇ /loki/api/v1/push                  ‚îÇ
‚îÇ                         ‚ñº                                    ‚îÇ
‚îÇ                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îÇ
‚îÇ                ‚îÇ      Loki       ‚îÇ (External Server)         ‚îÇ
‚îÇ                ‚îÇ     :3100       ‚îÇ                           ‚îÇ
‚îÇ                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîß PostgreSQL Test Database

### C·∫•u h√¨nh Logging Chi ti·∫øt

PostgreSQL trong m√¥i tr∆∞·ªùng n√†y ƒë∆∞·ª£c c·∫•u h√¨nh ƒë·ªÉ log **T·∫§T C·∫¢** ho·∫°t ƒë·ªông. ƒê√¢y l√† ƒëi·ªÅu b·∫°n **KH√îNG N√äN** l√†m trong production.

#### T·∫°i sao log ALL statements?

**Use cases:**
- **Audit**: Bi·∫øt ch√≠nh x√°c ai ƒë√£ ch·∫°y query g√¨, khi n√†o
- **Debug**: Reproduce l·ªói b·∫±ng c√°ch replay queries
- **Performance analysis**: T√¨m N+1 queries, missing indexes
- **Security**: Ph√°t hi·ªán SQL injection attempts

**Trade-offs:**
```
Pros:
‚úÖ Visibility ho√†n to√†n
‚úÖ Kh√¥ng miss b·∫•t k·ª≥ query n√†o
‚úÖ D·ªÖ debug

Cons:
‚ùå Log volume c·ª±c l·ªõn (GB/day)
‚ùå I/O overhead (~5-10% performance)
‚ùå Disk space
‚ùå Noise (qu√° nhi·ªÅu th√¥ng tin)
```

#### Log Configuration Breakdown

```yaml
command: |
  postgres
  -c logging_collector=on
  -c log_directory=/var/lib/postgresql/data/pg_log
  -c log_filename=postgresql-%Y-%m-%d_%H%M%S.log
  -c log_min_duration_statement=0
  -c log_statement=all
  -c log_connections=on
  -c log_disconnections=on
  -c log_duration=on
  -c log_line_prefix='%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
```

**Gi·∫£i th√≠ch t·ª´ng tham s·ªë:**

**1. `logging_collector=on`**
- Enable background process thu th·∫≠p logs
- Logs ƒë∆∞·ª£c ghi v√†o files thay v√¨ stderr
- Cho ph√©p log rotation

**2. `log_directory` v√† `log_filename`**
```
/var/lib/postgresql/data/pg_log/postgresql-2025-12-30_153045.log
‚îÇ                                           ‚îÇ
‚îÇ                                           ‚îî‚îÄ Timestamp: YYYY-MM-DD_HHMMSS
‚îî‚îÄ Log directory
```

**T·∫°i sao timestamp trong filename?**
- M·ªói PostgreSQL restart = file m·ªõi
- D·ªÖ identify logs theo th·ªùi gian
- Log rotation t·ª± ƒë·ªông

**3. `log_min_duration_statement=0`**

**√ù nghƒ©a:** Log t·∫•t c·∫£ statements, k·ªÉ c·∫£ nhanh nh·∫•t.

```sql
-- Query 1ms ‚Üí Logged
SELECT * FROM users WHERE id = 1;

-- Query 0.1ms ‚Üí C≈©ng logged
SELECT 1;
```

**Production setting:**
```
log_min_duration_statement=100  # Ch·ªâ log queries > 100ms
```

**4. `log_statement=all`**

**Options:**
- `none`: Kh√¥ng log statements
- `ddl`: Ch·ªâ log DDL (CREATE, ALTER, DROP)
- `mod`: Log DDL + DML (INSERT, UPDATE, DELETE)
- `all`: Log t·∫•t c·∫£ (bao g·ªìm SELECT)

**Test environment:** `all` ƒë·ªÉ th·∫•y m·ªçi th·ª©  
**Production:** `ddl` ho·∫∑c `mod` (SELECT qu√° nhi·ªÅu)

**5. `log_connections=on` v√† `log_disconnections=on`**

**Output:**
```
2025-12-30 15:30:45 UTC [1234]: [1-1] user=testuser,db=testdb,app=psql,client=10.0.0.1 LOG: connection received: host=10.0.0.1 port=54321
2025-12-30 15:35:00 UTC [1234]: [2-1] user=testuser,db=testdb,app=psql,client=10.0.0.1 LOG: disconnection: session time: 0:04:15.123
```

**Use cases:**
- Track connection pool behavior
- Identify connection leaks
- Monitor concurrent connections
- Audit user access

**6. `log_duration=on`**

**Output:**
```
2025-12-30 15:30:45 UTC [1234]: [3-1] user=testuser,db=testdb LOG: duration: 123.456 ms  statement: SELECT * FROM users;
```

**K·∫øt h·ª£p v·ªõi `log_min_duration_statement`:**
- `log_min_duration_statement=0` + `log_duration=on`: Log t·∫•t c·∫£ v·ªõi duration
- `log_min_duration_statement=100`: Ch·ªâ log slow queries v·ªõi duration

**7. `log_line_prefix`**

**Format:** `'%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '`

**Placeholders:**
- `%t`: Timestamp (2025-12-30 15:30:45 UTC)
- `%p`: Process ID (1234)
- `%l`: Log line number trong session
- `%u`: Username (testuser)
- `%d`: Database name (testdb)
- `%a`: Application name (psql, pgAdmin, myapp)
- `%h`: Client hostname/IP (10.0.0.1)

**T·∫°i sao structured prefix?**
```
2025-12-30 15:30:45 UTC [1234]: [3-1] user=testuser,db=testdb,app=myapp,client=10.0.0.1 LOG: duration: 123.456 ms
‚îÇ                               ‚îÇ         ‚îÇ                                                  ‚îÇ
‚îÇ                               ‚îÇ         ‚îÇ                                                  ‚îî‚îÄ Log message
‚îÇ                               ‚îÇ         ‚îî‚îÄ Context (d·ªÖ parse)
‚îÇ                               ‚îî‚îÄ Process ID
‚îî‚îÄ Timestamp
```

**Promtail c√≥ th·ªÉ parse:**
```yaml
regex:
  expression: '^(?P<timestamp>...) \[(?P<pid>\d+)\]: ... user=(?P<user>[^,]*),db=(?P<database>[^,]*)...'
```

‚Üí Extract th√†nh labels ƒë·ªÉ filter trong Grafana:
```logql
{service="postgresql", user="admin", database="production"}
```

#### Additional Logging Features

**Trong `postgresql.conf`:**

```ini
log_checkpoints = on
log_lock_waits = on
log_temp_files = 0
log_autovacuum_min_duration = 0
```

**1. `log_checkpoints=on`**

**Checkpoint** = PostgreSQL flush dirty pages t·ª´ memory ‚Üí disk.

**Log output:**
```
LOG: checkpoint starting: time
LOG: checkpoint complete: wrote 1234 buffers (7.5%); 0 WAL file(s) added, 0 removed, 1 recycled; write=0.123 s, sync=0.045 s, total=0.234 s
```

**T·∫°i sao quan tr·ªçng?**
- Checkpoints qu√° th∆∞·ªùng xuy√™n ‚Üí I/O spike ‚Üí slow queries
- Tune `checkpoint_timeout`, `max_wal_size` d·ª±a v√†o logs

**2. `log_lock_waits=on`**

**Log khi query ph·∫£i ch·ªù lock > `deadlock_timeout` (default 1s):**
```
LOG: process 1234 still waiting for ShareLock on transaction 5678 after 1000.123 ms
DETAIL: Process holding the lock: 5678. Wait queue: 1234, 1235.
```

**Use cases:**
- Identify lock contention
- Find queries causing blocking
- Optimize transaction isolation levels

**3. `log_temp_files=0`**

**Log khi query t·∫°o temporary files (work_mem kh√¥ng ƒë·ªß):**
```
LOG: temporary file: path "base/pgsql_tmp/pgsql_tmp1234.0", size 104857600
STATEMENT: SELECT * FROM large_table ORDER BY created_at;
```

**√ù nghƒ©a:**
- Query d√πng disk thay v√¨ RAM ‚Üí ch·∫≠m
- C·∫ßn tƒÉng `work_mem` ho·∫∑c optimize query

**4. `log_autovacuum_min_duration=0`**

**Log t·∫•t c·∫£ autovacuum operations:**
```
LOG: automatic vacuum of table "testdb.public.users": index scans: 1
    pages: 0 removed, 1234 remain, 0 skipped due to pins
    tuples: 567 removed, 12345 remain, 0 are dead but not yet removable
    buffer usage: 234 hits, 56 misses, 12 dirtied
    avg read rate: 1.234 MB/s, avg write rate: 0.567 MB/s
    system usage: CPU: user: 0.12 s, system: 0.03 s, elapsed: 1.23 s
```

**T·∫°i sao quan tr·ªçng?**
- Autovacuum ch·∫≠m ‚Üí table bloat ‚Üí slow queries
- Tune autovacuum parameters d·ª±a v√†o logs

### PostgreSQL Exporter

**Vai tr√≤:** Chuy·ªÉn ƒë·ªïi PostgreSQL internal stats th√†nh Prometheus metrics.

#### C√°ch ho·∫°t ƒë·ªông

```
1. Exporter k·∫øt n·ªëi PostgreSQL:
   postgresql://testuser:testpass@postgres-test:5432/testdb

2. Ch·∫°y SQL queries:
   SELECT * FROM pg_stat_database;
   SELECT * FROM pg_stat_activity;
   SELECT * FROM pg_stat_user_tables;
   ...

3. Parse k·∫øt qu·∫£ ‚Üí Prometheus format:
   pg_stat_database_xact_commit{datname="testdb"} 12345
   pg_stat_activity_count{state="active"} 5

4. Expose qua HTTP:
   http://postgres-exporter:9187/metrics
```

#### Key Metrics

**Database-level:**
```promql
# Transaction rate
rate(pg_stat_database_xact_commit[5m])
rate(pg_stat_database_xact_rollback[5m])

# Rollback ratio (should be low)
rate(pg_stat_database_xact_rollback[5m]) 
/ 
rate(pg_stat_database_xact_commit[5m])

# Database size
pg_database_size_bytes{datname="testdb"}
```

**Connection stats:**
```promql
# Active connections
pg_stat_activity_count{state="active"}

# Idle connections
pg_stat_activity_count{state="idle"}

# Idle in transaction (bad!)
pg_stat_activity_count{state="idle in transaction"}
```

**T·∫°i sao "idle in transaction" x·∫•u?**
- Gi·ªØ locks
- Block autovacuum
- Waste connection slots

**Table stats:**
```promql
# Sequential scans (should be low for large tables)
pg_stat_user_tables_seq_scan{relname="users"}

# Index scans (should be high)
pg_stat_user_tables_idx_scan{relname="users"}

# Seq scan ratio
pg_stat_user_tables_seq_scan 
/ 
(pg_stat_user_tables_seq_scan + pg_stat_user_tables_idx_scan)
```

**High seq scan ratio ‚Üí Missing indexes**

#### Exporter Configuration

```yaml
environment:
  - DATA_SOURCE_NAME=postgresql://testuser:testpass@postgres-test:5432/testdb?sslmode=disable
  - PG_EXPORTER_AUTO_DISCOVER_DATABASES=true
  - PG_EXPORTER_EXCLUDE_DATABASES=template0,template1
```

**`AUTO_DISCOVER_DATABASES=true`:**
- T·ª± ƒë·ªông monitor t·∫•t c·∫£ databases
- Kh√¥ng c·∫ßn config m·ªói database ri√™ng

**`EXCLUDE_DATABASES`:**
- `template0`, `template1`: System databases
- Kh√¥ng c√≥ user data ‚Üí kh√¥ng c·∫ßn monitor

## üîß MongoDB Test Database

### Logging v√† Profiling

MongoDB s·ª≠ d·ª•ng **structured JSON logs** v√† **operation profiling**.

#### System Log Configuration

```yaml
systemLog:
  destination: file
  path: /var/log/mongodb/mongod.log
  logAppend: true
  logRotate: reopen
  verbosity: 1
  component:
    accessControl:
      verbosity: 1
    command:
      verbosity: 2
    query:
      verbosity: 2
```

**Verbosity levels:**
- `0`: Info (default)
- `1`: Debug
- `2`: Fine-grained debug
- `3-5`: Trace (c·ª±c k·ª≥ chi ti·∫øt)

**Component-specific verbosity:**

**1. `command: verbosity: 2`**
- Log t·∫•t c·∫£ commands (insert, update, delete, find)
- Include command details v√† execution time

**2. `query: verbosity: 2`**
- Log query planning
- Index selection
- Query optimization

**Log format (JSON):**
```json
{
  "t": {"$date": "2025-12-30T15:30:45.123Z"},
  "s": "I",
  "c": "COMMAND",
  "ctx": "conn123",
  "msg": "command executed",
  "attr": {
    "command": "find",
    "collection": "users",
    "filter": {"age": {"$gt": 18}},
    "planSummary": "IXSCAN { age: 1 }",
    "durationMillis": 45
  }
}
```

**Fields:**
- `t.$date`: Timestamp (ISO 8601)
- `s`: Severity (I=Info, W=Warning, E=Error)
- `c`: Component (COMMAND, QUERY, STORAGE, etc.)
- `ctx`: Context (connection ID)
- `msg`: Message
- `attr`: Attributes (structured data)

#### Operation Profiling

```yaml
operationProfiling:
  mode: all
  slowOpThresholdMs: 0
  slowOpSampleRate: 1.0
```

**Profiling modes:**
- `off`: Disabled
- `slowOp`: Ch·ªâ log slow operations
- `all`: Log t·∫•t c·∫£ operations (test environment)

**`slowOpThresholdMs: 0`:**
- Threshold = 0ms ‚Üí t·∫•t c·∫£ operations ƒë·ªÅu "slow"
- K·∫øt h·ª£p `mode: all` ‚Üí profile 100%

**`slowOpSampleRate: 1.0`:**
- 1.0 = 100% sampling
- 0.1 = 10% sampling (production)

**Profiler output (trong system log):**
```json
{
  "s": "I",
  "c": "COMMAND",
  "msg": "Slow query",
  "attr": {
    "type": "command",
    "ns": "testdb.users",
    "command": {
      "find": "users",
      "filter": {"age": {"$gt": 18}}
    },
    "planSummary": "COLLSCAN",
    "durationMillis": 234,
    "numYields": 5,
    "nreturned": 1000,
    "docsExamined": 10000,
    "keysExamined": 0
  }
}
```

**Key metrics:**
- `durationMillis`: Execution time
- `planSummary`: IXSCAN (good) vs COLLSCAN (bad)
- `docsExamined`: Documents scanned
- `nreturned`: Documents returned
- `keysExamined`: Index entries scanned

**Efficiency ratio:**
```
docsExamined / nreturned = 10000 / 1000 = 10

Ideal: Ratio = 1 (m·ªói doc scan = 1 doc return)
Bad: Ratio > 10 (scan nhi·ªÅu, return √≠t)
```

### MongoDB Exporter

#### Metrics Collection

**Exporter ch·∫°y MongoDB commands:**
```javascript
db.serverStatus()
db.stats()
db.getReplicationInfo()
```

**Key metrics:**

**Operations:**
```promql
# Operation counters
rate(mongodb_op_counters_total{type="query"}[5m])
rate(mongodb_op_counters_total{type="insert"}[5m])
rate(mongodb_op_counters_total{type="update"}[5m])
rate(mongodb_op_counters_total{type="delete"}[5m])
```

**Latency:**
```promql
# Average read latency (microseconds)
rate(mongodb_ss_opLatencies_latency{type="reads"}[5m]) 
/ 
rate(mongodb_ss_opLatencies_ops{type="reads"}[5m])

# Convert to milliseconds
(...) / 1000
```

**Connections:**
```promql
# Current connections
mongodb_connections{conn_type="current"}

# Available connections
mongodb_connections{conn_type="available"}

# Connection usage %
mongodb_connections{conn_type="current"} 
/ 
(mongodb_connections{conn_type="current"} + mongodb_connections{conn_type="available"}) 
* 100
```

**WiredTiger Cache:**
```promql
# Cache hit ratio
rate(mongodb_mongod_wiredtiger_cache_pages_requested_from_cache_total[5m])
/
(
  rate(mongodb_mongod_wiredtiger_cache_pages_requested_from_cache_total[5m])
  +
  rate(mongodb_mongod_wiredtiger_cache_pages_read_total[5m])
)

# Should be > 0.95 (95%)
```

#### Exporter Flags

```yaml
command:
  - "--mongodb.uri=mongodb://admin:pass@mongodb-test:27017"
  - "--collect-all"
  - "--compatible-mode"
  - "--collector.replicasetstatus"
  - "--discovering-mode"
```

**`--collect-all`:**
- Default: Ch·ªâ collect basic metrics
- Flag n√†y: Collect t·∫•t c·∫£ metrics available

**`--compatible-mode`:**
- H·ªó tr·ª£ MongoDB 3.x, 4.x, 5.x, 6.x, 7.x
- T·ª± ƒë·ªông detect version v√† adjust queries

**`--collector.replicasetstatus`:**
- Enable replica set metrics
- Replication lag, member health, etc.

**`--discovering-mode`:**
- T·ª± ƒë·ªông discover databases v√† collections
- Monitor t·∫•t c·∫£ databases, kh√¥ng c·∫ßn config ri√™ng

## üîß Promtail - Database Log Collector

### PostgreSQL Log Pipeline

```yaml
- job_name: postgresql
  static_configs:
    - targets: [localhost]
      labels:
        job: postgresql
        service_name: postgresql-log-test
        db_type: postgres
        host: 10.99.3.67
        instance: test
        __path__: /var/log/postgres/**/*.log
```

**`__path__: /var/log/postgres/**/*.log`:**
- `**`: Recursive glob
- Match: `/var/log/postgres/pg_log/postgresql-2025-12-30_153045.log`

#### Pipeline Stages

**1. Multiline Stage**

```yaml
- multiline:
    firstline: '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}'
    max_wait_time: 3s
```

**V·∫•n ƒë·ªÅ:** SQL queries c√≥ th·ªÉ span nhi·ªÅu lines:
```
2025-12-30 15:30:45 UTC [1234]: [3-1] user=testuser,db=testdb LOG: duration: 123.456 ms  statement: SELECT *
FROM users
WHERE age > 18
  AND city = 'Hanoi'
ORDER BY created_at DESC;
```

**Gi·∫£i ph√°p:**
- `firstline`: Regex match d√≤ng ƒë·∫ßu (c√≥ timestamp)
- C√°c d√≤ng sau kh√¥ng match ‚Üí append v√†o log entry tr∆∞·ªõc
- `max_wait_time: 3s`: Ch·ªù t·ªëi ƒëa 3s cho d√≤ng ti·∫øp theo

**2. Regex Parsing**

```yaml
- regex:
    expression: '^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:\.\d+)? \w+) \[(?P<pid>\d+)\]: \[(?P<line_num>\d+-\d+)\] user=(?P<user>[^,]*),db=(?P<database>[^,]*),app=(?P<application>[^,]*),client=(?P<client>[^ ]*) (?P<level>\w+):\s+(?P<message>.*)'
```

**Parse:**
```
Input:
2025-12-30 15:30:45 UTC [1234]: [3-1] user=testuser,db=testdb,app=myapp,client=10.0.0.1 LOG: duration: 123.456 ms

Extracted:
timestamp: "2025-12-30 15:30:45 UTC"
pid: "1234"
line_num: "3-1"
user: "testuser"
database: "testdb"
application: "myapp"
client: "10.0.0.1"
level: "LOG"
message: "duration: 123.456 ms"
```

**3. Labels Stage**

```yaml
- labels:
    user:
    database:
    application:
    level:
```

**Promote extracted fields ‚Üí Loki labels:**
```
{
  job="postgresql",
  service_name="postgresql-log-test",
  user="testuser",
  database="testdb",
  application="myapp",
  level="LOG"
}
```

**Query trong Grafana:**
```logql
{service_name="postgresql-log-test", database="production", level="ERROR"}
```

**4. Template Stage**

```yaml
- template:
    source: application
    template: '{{ if eq .Value "[unknown]" }}undefined{{ else }}{{ .Value }}{{ end }}'
```

**X·ª≠ l√Ω edge case:**
- PostgreSQL log `app=[unknown]` khi kh√¥ng set application_name
- Template replace `[unknown]` ‚Üí `undefined`

**5. Timestamp Stage**

```yaml
- timestamp:
    source: timestamp
    format: '2006-01-02 15:04:05 MST'
```

**Parse timestamp t·ª´ log ‚Üí Loki timestamp:**
- `source: timestamp`: Field ƒë√£ extract
- `format`: Go time format (2006-01-02 = reference date)

**T·∫°i sao quan tr·ªçng?**
- Loki index theo timestamp
- Query by time range ch√≠nh x√°c

**6. Output Stage**

```yaml
- output:
    source: message
```

**Final log line = ch·ªâ message:**
```
Before: 2025-12-30 15:30:45 UTC [1234]: [3-1] user=testuser,db=testdb,app=myapp,client=10.0.0.1 LOG: duration: 123.456 ms

After: duration: 123.456 ms
```

**T·∫°i sao?**
- Timestamp, user, database, etc. ƒë√£ l√† labels
- Log line ch·ªâ c·∫ßn message
- Gi·∫£m storage, d·ªÖ ƒë·ªçc

### MongoDB Log Pipeline

```yaml
- job_name: mongodb
  static_configs:
    - targets: [localhost]
      labels:
        job: mongodb
        service_name: mongodb-log-test
        db_type: mongodb
        __path__: /var/log/mongodb/*.log
```

#### Pipeline Stages

**1. JSON Parsing**

```yaml
- json:
    expressions:
      timestamp: t."$date"
      severity: s
      component: c
      context: ctx
      message: msg
      attr: attr
```

**MongoDB log (JSON):**
```json
{
  "t": {"$date": "2025-12-30T15:30:45.123Z"},
  "s": "I",
  "c": "COMMAND",
  "ctx": "conn123",
  "msg": "Slow query",
  "attr": {"durationMillis": 234}
}
```

**Extracted:**
- `timestamp`: `"2025-12-30T15:30:45.123Z"` (nested field `t.$date`)
- `severity`: `"I"`
- `component`: `"COMMAND"`
- `context`: `"conn123"`
- `message`: `"Slow query"`
- `attr`: `{"durationMillis": 234}` (entire object)

**2. Labels**

```yaml
- labels:
    severity:
    component:
```

**Loki labels:**
```
{
  job="mongodb",
  service_name="mongodb-log-test",
  severity="I",
  component="COMMAND"
}
```

**Query:**
```logql
# Errors and warnings
{service_name="mongodb-log-test", severity=~"E|W"}

# Query-related logs
{service_name="mongodb-log-test", component="QUERY"}
```

**3. Timestamp**

```yaml
- timestamp:
    source: timestamp
    format: RFC3339
```

**RFC3339:** `2025-12-30T15:30:45.123Z`

**4. Output**

```yaml
- output:
    source: message
```

**Final log:**
```
Slow query
```

**Attributes (attr) ƒëi ƒë√¢u?**
- Kh√¥ng extract th√†nh labels (high cardinality)
- V·∫´n trong log line (JSON string)
- Query v·ªõi `| json | attr_durationMillis > 100`

## üí° S·ª≠ d·ª•ng Logs v√† Metrics

### PostgreSQL Use Cases

**1. T√¨m slow queries:**

**Logs:**
```logql
{service_name="postgresql-log-test"} 
  |= "duration:" 
  | regexp "duration: (?P<duration>\\d+\\.\\d+) ms" 
  | duration > 100
```

**Metrics:**
```promql
# Long running queries
pg_stat_activity_max_tx_duration{state="active"} > 300
```

**2. Monitor connections:**

**Metrics:**
```promql
# Connection count
pg_stat_activity_count

# Connection usage %
pg_stat_activity_count 
/ 
pg_settings_max_connections 
* 100
```

**Logs:**
```logql
# Connection events
{service_name="postgresql-log-test"} |~ "connection (received|authorized|disconnection)"
```

**3. Identify missing indexes:**

**Metrics:**
```promql
# Sequential scan ratio
pg_stat_user_tables_seq_scan 
/ 
(pg_stat_user_tables_seq_scan + pg_stat_user_tables_idx_scan)
```

**Logs:**
```logql
# Queries creating temp files (work_mem exceeded)
{service_name="postgresql-log-test"} |= "temporary file"
```

### MongoDB Use Cases

**1. Slow queries:**

**Logs:**
```logql
{service_name="mongodb-log-test", component="COMMAND"} 
  | json 
  | attr_durationMillis > 100
```

**Metrics:**
```promql
# Average query latency
rate(mongodb_ss_opLatencies_latency{type="commands"}[5m]) 
/ 
rate(mongodb_ss_opLatencies_ops{type="commands"}[5m]) 
/ 1000  # Convert to ms
```

**2. Collection scans (missing indexes):**

**Logs:**
```logql
{service_name="mongodb-log-test"} 
  | json 
  | attr_planSummary = "COLLSCAN"
```

**3. Connection issues:**

**Metrics:**
```promql
# Connection pool exhaustion
mongodb_connections{conn_type="available"} < 10
```

**Logs:**
```logql
{service_name="mongodb-log-test", component="NETWORK"}
```

## üéì T·ªïng k·∫øt

### Database Monitoring Flow

```
1. Databases log operations
   ‚îú‚îÄ PostgreSQL: Text logs v·ªõi structured prefix
   ‚îî‚îÄ MongoDB: JSON logs

2. Exporters collect metrics
   ‚îú‚îÄ Query database stats
   ‚îî‚îÄ Expose Prometheus metrics

3. Promtail collects logs
   ‚îú‚îÄ Parse logs (regex/JSON)
   ‚îú‚îÄ Extract labels
   ‚îî‚îÄ Push to Loki

4. Prometheus scrapes metrics
   ‚îî‚îÄ Store time series

5. Grafana visualizes
   ‚îú‚îÄ Metrics dashboards
   ‚îî‚îÄ Log exploration
```

### Key Takeaways

‚úÖ **Test environment** = Full logging ƒë·ªÉ h·ªçc v√† experiment  
‚úÖ **PostgreSQL** = Text logs, structured prefix, ALL statements  
‚úÖ **MongoDB** = JSON logs, operation profiling 100%  
‚úÖ **Exporters** = Metrics t·ª´ database internal stats  
‚úÖ **Promtail** = Parse logs, extract labels, multiline support  
‚úÖ **Logs + Metrics** = Complete visibility  

### Production Recommendations

Khi √°p d·ª•ng l√™n production, ƒëi·ªÅu ch·ªânh:

**PostgreSQL:**
```ini
log_min_duration_statement = 100  # Ch·ªâ slow queries
log_statement = 'ddl'             # Ch·ªâ DDL
```

**MongoDB:**
```yaml
operationProfiling:
  mode: slowOp
  slowOpThresholdMs: 100
  slowOpSampleRate: 0.1  # 10% sampling
systemLog:
  verbosity: 0  # Info only
```

**Trade-off:**
- Test: 100% visibility, high overhead
- Production: Balanced visibility, low overhead
